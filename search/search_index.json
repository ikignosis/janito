{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Janito Documentation","text":"<p>Welcome to the Janito documentation! This site contains comprehensive guides, tutorials, and reference materials for using and extending Janito.</p>"},{"location":"#what-is-janito","title":"What is Janito?","text":"<p>Janito is a powerful AI assistant designed for developers, providing intelligent code assistance, terminal integration, and extensible tooling capabilities.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ul> <li>Installation Guide - Get Janito up and running</li> <li>Quickstart &amp; Basic Usage - Learn the basics</li> <li>Configuration - Set up Janito for your needs</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Terminal Integration: Seamless shell integration with intelligent command assistance</li> <li>Code Intelligence: Advanced code analysis and generation capabilities</li> <li>Extensible Tools: Custom tool development and integration</li> <li>Multi-Provider Support: Works with OpenAI, DeepSeek, MoonshotAI, and more</li> <li>Human-Guided AI: Collaborative AI that works with you, not instead of you</li> </ul>"},{"location":"#documentation-sections","title":"Documentation Sections","text":""},{"location":"#using-janito","title":"Using Janito","text":"<p>Learn how to use Janito effectively: - Terminal Shell - Interactive terminal sessions - Single-Shot Commands - One-off command execution - Profiles - Custom configurations for different workflows</p>"},{"location":"#development-extension","title":"Development &amp; Extension","text":"<p>For developers looking to extend Janito: - Developer Guide - Core development concepts - Tools Developer Guide - Creating custom tools - Developer Toolchain - Development setup and workflows</p>"},{"location":"#supported-providers","title":"Supported Providers","text":"<p>Janito supports multiple AI providers: - OpenAI - DeepSeek - MoonshotAI - Z.ai - Cerebras</p>"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>Check our troubleshooting guides</li> <li>Review common issues</li> <li>Explore alternative solutions</li> </ul> <p>This documentation is automatically deployed from the latest commit and will always reflect the most current version of Janito.</p>"},{"location":"DIV/","title":"DIV","text":"<p>Perfect! Here's your finalized framework titled:</p>"},{"location":"DIV/#div-discovery-implementation-validation","title":"DIV: Discovery, Implementation, Validation","text":""},{"location":"DIV/#a-structured-workflow-for-handling-software-development-requests-with-context-clarity-and-validation","title":"A structured workflow for handling software development requests with context, clarity, and validation.","text":""},{"location":"DIV/#1-discovery","title":"\ud83d\udfe6 1. Discovery","text":"<p>Understand the request in project context.</p> <ul> <li>Inputs: Request, codebase, documentation, issues/PRs  </li> <li>Activities: Clarify intent, cross-check knowledge, map to components  </li> <li>Outputs: Scoped problem statement, mapping to files/issues</li> </ul>"},{"location":"DIV/#2-implementation","title":"\ud83d\udfe8 2. Implementation","text":"<p>Deliver a change or provide clarity.</p> <ul> <li>Inputs: Scoped request, project artifacts  </li> <li>Activities: Code/config/doc changes OR explanation  </li> <li>Outputs: PR/commit, updated docs, or clear resolution</li> </ul>"},{"location":"DIV/#3-validation","title":"\ud83d\udfe9 3. Validation","text":"<p>Confirm correctness of both understanding and change.</p> <ul> <li>Inputs: Delivered solution or response, feedback  </li> <li>Activities: Review, test, confirm with requester  </li> <li>Outputs: Merged change, validated answer, closed task</li> </ul> <p>\ud83d\udd01 Iterative Flow: If validation reveals misalignment, loop back to Discovery or Implementation with refined understanding.</p> <p>This DIV framework offers a clean, repeatable model for handling requests \u2014 from bug fixes and enhancements to clarifications and investigations \u2014 all while staying grounded in the real state of your project.</p>"},{"location":"TOOLBAR-STYLING/","title":"Styling the Prompt Toolkit Toolbar in Janito","text":"<p>This document describes how styles are defined and applied to key elements in the command-line interface (CLI) toolbar using prompt_toolkit.</p>"},{"location":"TOOLBAR-STYLING/#how-toolbar-styling-works","title":"How Toolbar Styling Works","text":"<ul> <li>The toolbar lines (provider, model, role, key bindings, token usage, etc.) are generated in <code>janito/cli/chat_mode/toolbar.py</code>.</li> <li>The strings use special HTML-like tags (e.g., <code>&lt;role&gt;admin&lt;/role&gt;</code>, <code>&lt;key-label&gt;F1&lt;/key-label&gt;</code>) to mark segments for custom styling.</li> <li><code>prompt_toolkit</code>'s <code>HTML</code> formatted text parser interprets tags that match style names defined in a dictionary in <code>janito/cli/chat_mode/prompt_style.py</code>.</li> </ul>"},{"location":"TOOLBAR-STYLING/#defining-styles","title":"Defining Styles","text":"<p>All style rules are set in <code>janito/cli/chat_mode/prompt_style.py</code>, for example:</p> <pre><code>chat_shell_style = Style.from_dict({\n    'role': 'fg:#e87c32 bold',                # For &lt;role&gt;...&lt;/role&gt;\n    'provider': 'fg:#117fbf',                 # For &lt;provider&gt;...&lt;/provider&gt;\n    'key-label': 'bg:#ff9500 fg:#232323 bold',# For &lt;key-label&gt;...&lt;/key-label&gt;\n    ...\n})\n</code></pre> <ul> <li>The key in <code>Style.from_dict</code> must match the tag name used in toolbar line strings.</li> <li>Example: <code>&lt;role&gt;user&lt;/role&gt;</code> will be rendered using the <code>'role'</code> style.</li> </ul>"},{"location":"TOOLBAR-STYLING/#applying-styles-in-toolbar-output","title":"Applying Styles in Toolbar Output","text":"<p>When building toolbar lines, use HTML-like tags named for your style, not CSS style tags or attributes:</p> <p>Correct:</p> <pre><code>f'Press &lt;key-label&gt;F1&lt;/key-label&gt; for help | Role: &lt;role&gt;{role}&lt;/role&gt;'\n</code></pre> <p>Incorrect (won't work):</p> <pre><code>f'&lt;style class=\"key-label\"&gt;F1&lt;/style&gt; | Role: &lt;role&gt;{role}&lt;/role&gt;'\n</code></pre>"},{"location":"TOOLBAR-STYLING/#supported-tag-mapping","title":"Supported Tag Mapping","text":"Tag Used in Toolbar String Style Name in prompt_style.py Example Usage <code>&lt;role&gt;...&lt;/role&gt;</code> <code>'role'</code> <code>&lt;role&gt;user&lt;/role&gt;</code> <code>&lt;provider&gt;...&lt;/provider&gt;</code> <code>'provider'</code> <code>&lt;provider&gt;OpenAI&lt;/provider&gt;</code> <code>&lt;key-label&gt;...&lt;/key-label&gt;</code> <code>'key-label'</code> <code>&lt;key-label&gt;F1&lt;/key-label&gt;</code> <code>&lt;msg_count&gt;...&lt;/msg_count&gt;</code> <code>'msg_count'</code> <code>&lt;msg_count&gt;3&lt;/msg_count&gt;</code> ... ... ..."},{"location":"TOOLBAR-STYLING/#adding-or-changing-a-style","title":"Adding or Changing a Style","text":"<ol> <li>Define your style in <code>prompt_style.py</code>, for example:    <code>python    'custom': 'bg:#f7e01d fg:#222222'</code></li> <li>Mark up your toolbar string with <code>&lt;custom&gt;...&lt;/custom&gt;</code>.</li> <li>Result: prompt_toolkit will apply your custom style to those segments.</li> </ol>"},{"location":"TOOLBAR-STYLING/#example","title":"Example","text":"<p>If you want a new binding to stand out in blue:</p> <pre><code># In prompt_style.py:\n'blue-label': 'bg:#2629d4 fg:#ffffff bold',\n\n# In toolbar.py:\nreturn f'... &lt;blue-label&gt;F5&lt;/blue-label&gt;: Extra ...'\n</code></pre> <p>Troubleshooting: - If your style is not applied, check that the tag name in your string exactly matches a key in the style <code>from_dict</code>. - Do not use HTML <code>&lt;span&gt;</code>, <code>&lt;style&gt;</code>, or CSS classes; only tag names matching style dict keys work.</p> <p>See also: <code>prompt_toolkit.formatted_text.HTML</code> and prompt_toolkit styling documentation</p>"},{"location":"alibaba-setup/","title":"Alibaba Cloud Qwen Setup Guide","text":"<p>This guide explains how to set up the Alibaba Cloud Qwen provider for Janito.</p>"},{"location":"alibaba-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>An Alibaba Cloud account</li> <li>Access to the Alibaba Cloud Qwen model service</li> <li>API key for authentication</li> </ul>"},{"location":"alibaba-setup/#getting-your-api-key","title":"Getting Your API Key","text":"<ol> <li>Log in to your Alibaba Cloud account</li> <li>Navigate to the Qwen Model Service in the console</li> <li>Go to API Keys or Security Settings</li> <li>Create a new API key or use an existing one</li> <li>Copy the API key value</li> </ol>"},{"location":"alibaba-setup/#setting-up-the-api-key","title":"Setting Up the API Key","text":"<p>You can set your API key using the Janito CLI:</p> <pre><code>janito --set-api-key alibaba:your-api-key-here\n</code></pre> <p>Alternatively, you can set the environment variable:</p> <pre><code>export ALIBABA_API_KEY=your-api-key-here\n</code></pre>"},{"location":"alibaba-setup/#configuration","title":"Configuration","text":"<p>The Alibaba provider uses the following environment variable:</p> <ul> <li><code>ALIBABA_API_KEY</code>: Your Alibaba Cloud API key</li> </ul>"},{"location":"alibaba-setup/#available-models","title":"Available Models","text":"<p>The Alibaba provider supports the following models:</p> <ul> <li><code>qwen-turbo</code>: Fast, lightweight model for simple tasks</li> <li><code>qwen-plus</code>: Balanced performance and capability</li> <li><code>qwen-max</code>: Most capable model for complex tasks</li> <li><code>qwen3-coder-plus</code>: Coding-focused model with 128k context</li> <li><code>qwen3-coder-480b-a35b-instruct</code>: Advanced coding model</li> <li><code>qwen3-235b-a22b-thinking-2507</code>: 1M context thinking model</li> <li><code>qwen3-235b-a22b-instruct-2507</code>: 1M context instruct model</li> <li><code>qwen3-30b-a3b-thinking-2507</code>: 1M context thinking model</li> <li><code>qwen3-30b-a3b-instruct-2507</code>: 1M context instruct model</li> </ul>"},{"location":"alibaba-setup/#default-model","title":"Default Model","text":"<p>The default model is <code>qwen3-235b-a22b-instruct-2507</code>, which provides 129k context and is suitable for general-purpose tasks.</p>"},{"location":"alibaba-setup/#troubleshooting","title":"Troubleshooting","text":"<p>Q: I'm getting authentication errors A: Verify your API key is correct and has the necessary permissions in the Alibaba Cloud console.</p> <p>Q: The model is not responding A: Check your internet connection and verify the Alibaba Cloud Qwen service is available in your region.</p> <p>Q: I want to use a different model A: Use the <code>--model</code> flag when running Janito:</p> <pre><code>janito --provider alibaba --model qwen-max\n</code></pre>"},{"location":"alternatives/","title":"Alternatives to Janito","text":"<p>There are many tools for AI-powered code assistance and project automation. Here are some notable alternatives, grouped by category:</p> Category Name Description Link \ud83d\udfe2 Open Source CLI aider Fast, open-source GPT coding in your terminal. aider.chat \ud83d\udfe2 Open Source CLI RA.Aid Autonomous software development agent with multi-step planning, research, and implementation. CLI-based, supports shell command execution, web research, and integration with aider. github.com/ai-christianson/RA.Aid \ud83d\udfe2 Open Source CLI OpenAI Codex CLI Lightweight, open-source coding agent that runs in your terminal. github.com/openai/codex \ud83d\udfe2 Open Source CLI Continue Open-source autopilot for software development. Integrates with VS Code and JetBrains, supports multiple models, and enables conversational coding and project-wide edits. continue.dev \ud83d\udfe9 VS Code Extension roo code Open-source, model-agnostic AI coding assistant for VS Code. Supports multi-file edits, guarded command execution, and deep project context. roocode.com \ud83d\udfe9 VS Code Extension cline Open-source, collaborative AI coding agent for VS Code. Autonomous, extensible, and supports multiple models. cline.bot \ud83d\udfe6 IDE-Integrated Cursor AI-powered code editor based on VS Code, with deep context and refactoring. cursor.com \ud83d\udfe6 IDE-Integrated Windsurf AI coding assistant and IDE (formerly Codeium) for VS Code, JetBrains, and its own editor. windsurf.com \ud83d\udfe6 IDE-Integrated GitHub Copilot AI pair programmer for VS Code, JetBrains, and more. github.com/features/copilot \ud83d\udfea Commercial Assistant Claude Code Anthropic\u2019s Claude models with code-focused features. github.com/anthropics/claude-code \ud83d\udfea Commercial Assistant Amazon CodeWhisperer AI code suggestions in IDEs. aws.amazon.com/codewhisperer \ud83d\udfea Commercial Assistant Tabnine AI code completion for multiple editors. tabnine.com \ud83c\udf10 Web-Based Chat ChatGPT OpenAI\u2019s web-based conversational AI. chat.openai.com \ud83c\udf10 Web-Based Chat Gemini Google\u2019s AI chat for code and general tasks. gemini.google.com \ud83c\udf10 Web-Based Chat Copilot Web GitHub Copilot\u2019s browser-based chat. github.com/features/copilot \ud83c\udf10 Web-Based Chat Claude Anthropic\u2019s Claude conversational AI. claude.ai <p>Each tool has its own strengths, focus, and integration style. Janito is unique in its open, prompt-driven, and tool-based approach\u2014see the rest of the docs for what sets it apart!</p>"},{"location":"cerebras-setup/","title":"Cerebras Setup Guide","text":"<p>This guide will help you set up Janito to use Cerebras as an LLM provider.</p>"},{"location":"cerebras-setup/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Cerebras account</li> <li>An API key from Cerebras</li> </ol>"},{"location":"cerebras-setup/#getting-an-api-key","title":"Getting an API Key","text":"<ol> <li>Visit the Cerebras API Keys page</li> <li>Log in to your account</li> <li>Generate a new API key</li> <li>Copy the API key for use in Janito</li> </ol>"},{"location":"cerebras-setup/#configuration","title":"Configuration","text":"<p>To configure Janito to use Cerebras, you need to set your API key:</p> <pre><code>janito --set-api-key YOUR_CEREBRAS_API_KEY -p cerebras\n</code></pre> <p>Replace <code>YOUR_CEREBRAS_API_KEY</code> with the API key you obtained from Cerebras.</p>"},{"location":"cerebras-setup/#usage","title":"Usage","text":"<p>After setting up your API key, you can use Cerebras models with Janito:</p> <pre><code>janito -p cerebras \"Hello, how are you?\"\n</code></pre> <p>By default, Janito will use the <code>qwen-3-coder-480b</code> model. You can specify a different model if needed:</p> <pre><code>janito -p cerebras -m qwen-3-coder-480b \"Explain quantum computing\"\n</code></pre>"},{"location":"cerebras-setup/#available-models","title":"Available Models","text":"<p>Cerebras offers several models through their API:</p> <p>Production Models:</p> <ul> <li><code>llama-4-scout-17b-16e-instruct</code></li> <li><code>llama-3.3-70b</code></li> <li><code>llama3.1-8b</code></li> <li><code>qwen-3-32b</code></li> </ul> <p>Preview Models:</p> <ul> <li><code>llama-4-maverick-17b-128e-instruct</code></li> <li><code>qwen-3-235b-a22b-instruct-2507</code></li> <li><code>qwen-3-235b-a22b-thinking-2507</code></li> <li><code>qwen-3-coder-480b</code></li> <li><code>gpt-oss-120b</code></li> </ul> <p>Notes:</p> <ul> <li><code>qwen-3-coder-480b</code>: 32k context, reasoning-focused model with function calling support</li> </ul>"},{"location":"cerebras-setup/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues:</p> <ol> <li>Verify your API key is correct and active</li> <li>Check that you have internet connectivity</li> <li>Ensure you're using a supported model name</li> <li>Check the Cerebras status page for any service outages</li> </ol> <p>For further assistance, consult the Cerebras documentation or Janito documentation.</p>"},{"location":"deepseek-setup/","title":"Configuring Janito for DeepSeek","text":"<p>Janito supports DeepSeek as an LLM provider. This guide explains how to configure Janito to use DeepSeek models.</p>"},{"location":"deepseek-setup/#1-obtain-a-deepseek-api-key","title":"1. Obtain a DeepSeek API Key","text":"<ul> <li>Sign up or log in at DeepSeek to get your API key.</li> </ul>"},{"location":"deepseek-setup/#2-set-your-deepseek-api-key-in-janito","title":"2. Set Your DeepSeek API Key in Janito","text":"<p>You must specify both the API key and the provider name when configuring Janito for DeepSeek:</p> <pre><code>janito --set-api-key YOUR_DEEPSEEK_API_KEY -p deepseek\n</code></pre> <p>Replace <code>YOUR_DEEPSEEK_API_KEY</code> with your actual DeepSeek API key.</p>"},{"location":"deepseek-setup/#3-select-deepseek-as-the-provider","title":"3. Select DeepSeek as the Provider","text":"<p>You can set DeepSeek as your default provider:</p> <pre><code>janito --set provider=deepseek\n</code></pre> <p>Or specify it per command:</p> <pre><code>janito -p deepseek \"Your prompt here\"\n</code></pre>"},{"location":"deepseek-setup/#4-choose-a-deepseek-model","title":"4. Choose a DeepSeek Model","text":"<p>Janito supports the following DeepSeek models:</p> <ul> <li><code>deepseek-chat</code> (default)</li> <li><code>deepseek-reasoner</code></li> </ul> <p>To select a model:</p> <pre><code>janito -p deepseek -m deepseek-reasoner \"Your prompt here\"\n</code></pre>"},{"location":"deepseek-setup/#5-verify-your-configuration","title":"5. Verify Your Configuration","text":"<p>Show your current configuration (the config file path will be shown at the top):</p> <pre><code>janito --show-config\n</code></pre>"},{"location":"deepseek-setup/#6-troubleshooting","title":"6. Troubleshooting","text":"<ul> <li>Ensure your API key is correct and active.</li> <li>If you encounter issues, use <code>janito --list-providers</code> to verify DeepSeek is available.</li> <li>For more help, see the main Configuration Guide or run <code>janito --help</code>.</li> </ul> <p>For more details on supported models and features, see Supported Providers &amp; Models.</p>"},{"location":"driver-flow/","title":"OpenAI Driver Content Flow in Janito","text":"<p>This document explains the updated flow for how content and tool calls are processed in Janito, focusing on the new <code>ResponseReceived</code> event and agent logic. This supports both streaming and agent-tool interleaving for advanced use cases.</p>"},{"location":"driver-flow/#flow-overview","title":"Flow Overview","text":"<ol> <li> <p>Model Response Handling (Driver Layer)</p> <ul> <li>The entrypoint is <code>OpenAIModelDriver._process_driver_input</code> (in <code>janito/drivers/openai/driver.py</code>).</li> <li>The driver collects output from the model (including content parts, tool call suggestions, etc.), and emits a single <code>ResponseReceived</code> event (from <code>janito/driver_events.py</code>).</li> <li>This event contains all content, tool calls, normalized timestamps, and relevant metadata.</li> </ul> </li> <li> <p>Agent Decision Loop</p> <ul> <li>The agent (<code>LLMAgent</code>, in <code>janito/llm/agent.py</code>) processes the <code>ResponseReceived</code> event:<ul> <li>If the event includes tool calls, the agent invokes those tools using the <code>tools_adapter</code>, updates its conversation history with the tool calls and their results, and resubmits to the driver for a new response.</li> <li>If there are no tool calls, the agent yields the <code>ResponseReceived</code> event as output (ending the loop for that prompt).</li> </ul> </li> <li>This pattern enables fully automated tool-use loops, and naturally supports function-calling workflows (e.g., OpenAI function calling, tool-augmented LLMs).</li> </ul> </li> <li> <p>CLI Core Loop (Chat/Prompt Handler)</p> <ul> <li>In interactive (chat) mode, the CLI (<code>janito/cli/chat_mode/session.py</code>, within <code>ChatSession._chat_loop</code>) uses the <code>PromptHandler</code> to run the user's prompt. The handler now expects <code>ResponseReceived</code> events and handles terminal output accordingly.</li> </ul> </li> <li> <p>Event Reporting / Output</p> <ul> <li>The <code>RichTerminalReporter</code> (<code>janito/cli/rich_terminal_reporter.py</code>) is responsible for displaying content found in the <code>content_parts</code> field of <code>ResponseReceived</code> events.</li> <li>Only these high-level events are printed as main output, streamlining event handling logic and supporting new LLM APIs.</li> </ul> </li> </ol>"},{"location":"driver-flow/#sequence-diagram-updated","title":"Sequence Diagram (Updated)","text":"<pre><code>User prompt (in CLI)\n   \u2193\nPromptHandler.run_prompt \u2192 agent.chat() (yields final ResponseReceived)\n   \u2193\nOpenAI driver produces ResponseReceived (content+tools)\n   \u2193\nLLMAgent detects tool calls \u2192 executes via tools_adapter \u2192 extends history, repeats until no tool calls\n   \u2193\nResponseReceived with only content_parts (no tool calls)\n   \u2193\nRichTerminalReporter.on_ResponseReceived prints content\n</code></pre>"},{"location":"driver-flow/#key-classes-files","title":"Key Classes &amp; Files","text":"<ul> <li>janito/drivers/openai/driver.py: Implements the OpenAI driver and emits <code>ResponseReceived</code> events only.</li> <li>janito/driver_events.py: Defines the new <code>ResponseReceived</code> (and other) events.</li> <li>janito/llm/agent.py: Contains smart tool-handling agent event loop.</li> <li>janito/cli/prompt_core.py: Handles prompt execution and event iteration.</li> <li>janito/cli/rich_terminal_reporter.py: Handles printing content from <code>ResponseReceived</code> to the user.</li> <li>janito/cli/chat_mode/session.py: Interactive CLI chat session management.</li> </ul>"},{"location":"driver-flow/#notes","title":"Notes","text":"<ul> <li>This event-driven flow provides both streaming and agent-tool-in-the-loop logic for all drivers. It is compatible with OpenAI and other providers adopting similar response models.</li> <li>Tool/function calls from the model are now only seen in the aggregated <code>tool_calls</code> field of the <code>ResponseReceived</code> event.</li> <li>Consumers should migrate to listen for <code>ResponseReceived</code> events instead of the legacy granular events (<code>ContentPartFound</code>, etc.).</li> </ul> <p>For more information, see code comments in the affected files or reach out to the maintainers for architectural questions.</p>"},{"location":"driver-request-cancellation/","title":"Driver Request Cancellation in Janito","text":""},{"location":"driver-request-cancellation/#overview","title":"Overview","text":"<p>Driver request cancellation refers to the ability to halt or abort an in-progress request to an LLM driver (such as OpenAI, Anthropic, etc.) before it completes. This is important for responsive user interfaces, resource management, and handling user-initiated aborts (e.g., pressing Ctrl+C in the CLI).</p>"},{"location":"driver-request-cancellation/#current-handling","title":"Current Handling","text":"<p>Janito's core driver flow is event-driven and supports cooperative, programmatic cancellation of in-progress requests using a <code>threading.Event</code> (commonly named <code>cancel_event</code>). This event is passed through the agent and driver layers and can be set by the consumer to signal that the current request should be aborted as soon as possible.</p>"},{"location":"driver-request-cancellation/#how-cooperative-cancellation-works","title":"How Cooperative Cancellation Works","text":"<ul> <li>A <code>threading.Event</code> object is created and passed as <code>cancel_event</code> to the agent or driver interface (e.g., <code>agent.chat(..., cancel_event=cancel_event)</code>).</li> <li>Drivers and agents check the state of <code>cancel_event</code> at key points during request processing (before starting, after API calls, and during long-running operations).</li> <li>If <code>cancel_event.is_set()</code> returns True, the driver should abort further processing, avoid sending new requests, and clean up resources promptly.</li> <li>This allows both user-initiated (e.g., Ctrl+C) and programmatic cancellation (e.g., from a UI button or another thread).</li> </ul>"},{"location":"driver-request-cancellation/#user-initiated-cancellation","title":"User-Initiated Cancellation","text":"<ul> <li>In CLI mode, users may interrupt a request using standard terminal signals (e.g., Ctrl+C). The Python runtime will raise a <code>KeyboardInterrupt</code>, which is handled by the CLI session loop to stop further processing and clean up.</li> <li>The agent logic will set the <code>cancel_event</code> in response to user interruption, ensuring downstream drivers respond promptly.</li> </ul>"},{"location":"driver-request-cancellation/#agenttool-initiated-cancellation","title":"Agent/Tool-Initiated Cancellation","text":"<ul> <li>Agents, tools, or external consumers can programmatically set the <code>cancel_event</code> to abort an in-progress request.</li> <li>This enables responsive UIs and advanced workflows where cancellation may be triggered by logic other than user interruption.</li> </ul>"},{"location":"driver-request-cancellation/#implementation-details","title":"Implementation Details","text":"<ul> <li>The <code>cancel_event</code> is an optional field in the <code>DriverInput</code> dataclass (see <code>janito/llm/driver_input.py</code>).</li> <li>Drivers are expected to check for cancellation at the start of processing and after any blocking or long-running operation (see <code>janito/llm/driver.py</code> and driver subclasses).</li> <li>Example usage and code references are available in <code>docs/llm-drivers.md</code>.</li> </ul>"},{"location":"driver-request-cancellation/#future-directions","title":"Future Directions","text":"<ul> <li>Streaming APIs: For drivers that support streaming, partial results may be available up to the point of cancellation.</li> <li>Graceful Cleanup: Continued improvements to resource management and cleanup on cancellation are planned.</li> </ul>"},{"location":"driver-request-cancellation/#affected-flows-when-cancellation-is-performed-at-the-agent-level","title":"Affected Flows When Cancellation is Performed at the Agent Level","text":"<p>When a cancellation is triggered at the agent level (e.g., by setting the <code>cancel_event</code> or via user interruption such as Ctrl+C), the following flows are affected:</p> <ol> <li>Agent Main Loop (<code>chat</code> method): The main conversation loop passes the <code>cancel_event</code> to the driver and monitors for user interruptions. If a cancellation is detected, it stops further processing and signals downstream components.</li> <li>Event Processing (<code>_process_next_response</code>): This method waits for events from the driver. On user interruption, it creates a <code>RequestFinished</code> event with status <code>cancelled</code> and puts it in the input queue, propagating cancellation.</li> <li>Driver Input Preparation (<code>_prepare_driver_input</code>): The <code>cancel_event</code> is attached to the <code>DriverInput</code> object, ensuring it is available to the driver for cooperative cancellation.</li> <li>Driver Processing (<code>process_driver_input</code> in <code>LLMDriver</code> and subclasses):</li> <li>Before starting, the driver checks if <code>cancel_event</code> is set and aborts if so.</li> <li>After API calls (and during long-running operations in subclasses), the driver checks <code>cancel_event</code> again and aborts if set.</li> <li>If cancellation is detected, a <code>RequestFinished</code> event with status <code>cancelled</code> is emitted to the output queue.</li> <li>Tool/Function Execution (within <code>_handle_response_received</code>): If tool calls are in progress, cancellation may prevent further tool execution or message handling, depending on when the event is set.</li> </ol> <p>This cooperative cancellation mechanism ensures that all major flows\u2014agent loop, driver processing, and tool execution\u2014respond promptly to cancellation requests, providing a responsive and robust user experience.</p>"},{"location":"driver-request-cancellation/#recommendations","title":"Recommendations","text":"<ul> <li>Use the <code>cancel_event</code> mechanism for both user-initiated and programmatic cancellation.</li> <li>For UI or API integrations, expose a way to set the <code>cancel_event</code> to allow users or logic to abort requests.</li> <li>For more details, see <code>docs/llm-drivers.md</code> and the relevant code in <code>janito/llm/agent.py</code>, <code>janito/llm/driver.py</code>, and driver implementations.</li> </ul>"},{"location":"driver-request-cancellation/#references","title":"References","text":"<ul> <li>See <code>docs/llm-drivers.md</code> for architecture and example usage.</li> <li>See CLI session handling for interruption logic.</li> <li>See <code>janito/llm/driver_input.py</code>, <code>janito/llm/agent.py</code>, and driver implementations for code-level details.</li> </ul>"},{"location":"drivers/","title":"LLM Driver Architecture and Implementation Guide","text":"<p>This document describes the architecture of the LLM driver system in Janito, focusing on the <code>LLMDriver</code> base class and the requirements for implementing a new provider-specific driver. It uses the OpenAI driver as a reference example.</p>"},{"location":"drivers/#overview-the-llmdriver-base-class","title":"Overview: The <code>LLMDriver</code> Base Class","text":"<p>All LLM drivers in Janito inherit from the abstract base class <code>LLMDriver</code> (<code>janito/llm/driver.py</code>). This class provides a threaded, queue-based interface for interacting with language model APIs in a provider-agnostic way.</p>"},{"location":"drivers/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Threaded Operation: Each driver runs a background thread that processes requests from an input queue and emits results/events to an output queue.</li> <li>Standardized Events: Drivers emit standardized events (e.g., <code>RequestStarted</code>, <code>ResponseReceived</code>, <code>RequestFinished</code>) for downstream consumers.</li> <li>Provider Abstraction: The base class defines abstract methods for provider-specific logic, ensuring a uniform interface for all drivers.</li> </ul>"},{"location":"drivers/#required-abstract-methods","title":"Required Abstract Methods","text":"<p>To implement a new driver, you must subclass <code>LLMDriver</code> and implement the following methods:</p> <ul> <li><code>def _prepare_api_kwargs(self, config, conversation)</code></li> <li> <p>Prepare the keyword arguments for the provider API call, including model name, parameters, and tool schemas if needed.</p> </li> <li> <p><code>def _call_api(self, driver_input: DriverInput)</code></p> </li> <li> <p>Execute the provider API call using the prepared arguments. Should handle cancellation and error reporting.</p> </li> <li> <p><code>def _convert_completion_message_to_parts(self, message)</code></p> </li> <li> <p>Convert the provider's response message into a list of standardized <code>MessagePart</code> objects (e.g., text, tool calls).</p> </li> <li> <p><code>def convert_history_to_api_messages(self, conversation_history)</code></p> </li> <li> <p>Convert the internal conversation history to the format required by the provider's API (e.g., a list of dicts for OpenAI).</p> </li> <li> <p><code>def _get_message_from_result(self, result)</code></p> </li> <li>Extract the relevant message object from the provider's API result for further processing.</li> </ul>"},{"location":"drivers/#threading-and-queues","title":"Threading and Queues","text":"<ul> <li>Each driver instance has its own <code>input_queue</code> and <code>output_queue</code>.</li> <li>Use the <code>start()</code> method to launch the driver's background thread.</li> <li>Submit requests by putting <code>DriverInput</code> objects into <code>input_queue</code>.</li> <li>Listen for events/results by reading from <code>output_queue</code>.</li> </ul>"},{"location":"drivers/#implementing-a-new-driver-checklist","title":"Implementing a New Driver: Checklist","text":"<ol> <li>Subclass <code>LLMDriver</code>.</li> <li>Implement all required abstract methods listed above.</li> <li>Handle provider-specific configuration (e.g., API keys, endpoints) in your constructor or via config objects.</li> <li>Emit standardized events using the provided event classes (<code>RequestStarted</code>, <code>ResponseReceived</code>, <code>RequestFinished</code>).</li> <li>Support cancellation by checking the <code>cancel_event</code> in <code>DriverInput</code> before and after API calls.</li> <li>Convert conversation history to the provider's required format.</li> <li>Convert provider responses to standardized message parts for downstream processing.</li> </ol>"},{"location":"drivers/#example-openai-driver","title":"Example: OpenAI Driver","text":"<p>See <code>janito/drivers/openai/driver.py</code> for a complete example. Highlights: - Implements all required methods for the OpenAI API. - Handles tool/function call schemas if tools are present. - Converts conversation history to OpenAI's message format. - Extracts usage and other metadata from the API response. - Handles cancellation and error reporting robustly.</p>"},{"location":"drivers/#references","title":"References","text":"<ul> <li>Base class: <code>janito/llm/driver.py</code></li> <li>OpenAI driver: <code>janito/drivers/openai/driver.py</code></li> <li>Driver events: <code>janito/driver_events.py</code></li> </ul>"},{"location":"event-bus/","title":"Event Bus System Documentation","text":""},{"location":"event-bus/#overview","title":"Overview","text":"<p>The event bus is a central mechanism for publish/subscribe (pub/sub) communication in the system. It enables decoupled components to communicate by publishing and subscribing to events of various types.</p> <ul> <li>Location: <code>janito/event_bus/bus.py</code></li> <li>Singleton Instance: <code>event_bus</code></li> </ul>"},{"location":"event-bus/#event-architecture","title":"Event Architecture","text":"<ul> <li>Events are Python dataclasses (see <code>janito/event_types.py</code>) that represent occurrences or state changes in the system.</li> <li>Event Types are defined as subclasses of the base <code>Event</code> class (now located in <code>janito/event_bus/event.py</code>).</li> <li>Subscribers are functions or objects that listen for specific event types.</li> </ul>"},{"location":"event-bus/#defining-events","title":"Defining Events","text":"<ol> <li>Base Event Class:</li> <li>Located at <code>janito/event_bus/event.py</code>:      <code>python      from dataclasses import dataclass      from typing import ClassVar      @dataclass      class Event:          category: ClassVar[str] = \"generic\"</code></li> <li>Custom Event Types:</li> <li>Define new events by subclassing <code>Event</code> or its descendants in <code>janito/event_types.py</code>.</li> <li>Example:      <code>python      @dataclass      class RequestStarted(DriverEvent): class RequestFinished(DriverEvent):          payload: Any          # ...</code></li> </ol>"},{"location":"event-bus/#subscribing-to-events","title":"Subscribing to Events","text":"<p>To listen for events, subscribe a callback to an event type:</p> <pre><code>from janito.event_bus.bus import event_bus\nfrom janito.driver_events import RequestStarted, RequestFinished\n\ndef on_request_started(event):\n    print(f\"Request started: {event}\")\n\nevent_bus.subscribe(RequestStarted, on_request_started)\nevent_bus.subscribe(RequestFinished, on_request_finished)\n</code></pre>"},{"location":"event-bus/#unsubscribing-from-events","title":"Unsubscribing from Events","text":"<p>To stop listening:</p> <pre><code>event_bus.unsubscribe(RequestStarted, on_request_started)\nevent_bus.unsubscribe(RequestFinished, on_request_finished)\n</code></pre>"},{"location":"event-bus/#publishing-events","title":"Publishing Events","text":"<p>To notify subscribers of an event:</p> <pre><code>from janito.driver_events import RequestStarted, RequestFinished\nfrom janito.event_bus.bus import event_bus\n\nmy_event = RequestStarted(driver_name=\"driver1\", request_id=\"abc123\", payload={...})\nevent_bus.publish(my_event)\n</code></pre>"},{"location":"event-bus/#automatic-timestamping","title":"Automatic Timestamping","text":"<ul> <li>Every event published will have a <code>timestamp</code> attribute (UNIX epoch seconds) automatically set by the event bus.</li> <li>This is injected at publish time and is available to all subscribers:   <code>python   def on_request_started(event):       print(event.timestamp)  # Set automatically by event bus</code></li> </ul>"},{"location":"event-bus/#example","title":"Example","text":"<pre><code>from janito.driver_events import RequestStarted, RequestFinished\nfrom janito.event_bus.bus import event_bus\n\ndef log_event(event):\n    print(f\"[{event.timestamp}] Event: {event}\")\n\nevent_bus.subscribe(RequestStarted, log_event)\n\n# Later in code...\nevent = RequestStarted(driver_name=\"driver1\", request_id=\"abc123\", payload={\"foo\": \"bar\"})\nevent_bus.publish(event)\n</code></pre>"},{"location":"event-bus/#best-practices","title":"Best Practices","text":"<ul> <li>Do not manually add a <code>timestamp</code> field to event dataclasses; it is managed by the event bus.</li> <li>Use specific event types for clarity and maintainability.</li> <li>Unsubscribe handlers when they are no longer needed to avoid memory leaks.</li> </ul> <p>For more details, see the source code in <code>janito/event_bus/bus.py</code> and <code>janito/event_types.py</code>.</p>"},{"location":"llm-drivers-required-config/","title":"LLM Driver Required Config Pattern","text":"<p>Some LLM drivers (when implemented) may require additional configuration fields (beyond API key or model name) to operate correctly. The <code>required_config</code> class attribute is intended to enable each driver to declare these requirements explicitly, and for providers to validate config early. As of this writing, no LLM driver implementation is present in this directory; this document describes the intended pattern.</p>"},{"location":"llm-drivers-required-config/#how-to-use","title":"How to Use","text":"<ol> <li> <p>Declare requirements in your driver:</p> <p><code>python class AzureOpenAIModelDriver(OpenAIModelDriver):     required_config = {\"azure_endpoint\"}  # The config dict must contain this key.</code></p> </li> <li> <p>Validation on driver instantiation:</p> <p>Instantiation via <code>LLMProvider.get_driver_for_model</code> will check that all required fields are present in the passed config dict, and raise a <code>ValueError</code> if any are missing.</p> </li> <li> <p>Backwards compatible:</p> </li> <li>If <code>required_config</code> is not present, no validation is performed.</li> <li>Providers and code using drivers without required_config are unchanged.</li> </ol>"},{"location":"llm-drivers-required-config/#example-azure-openai","title":"Example: Azure OpenAI","text":"<p>If a model spec for Azure OpenAI uses <code>AzureOpenAIModelDriver</code>, the following config is required:</p> <pre><code>config = {\n    \"azure_endpoint\": \"https://example.openai.azure.com/\"\n}\n</code></pre> <p>Attempting to create the driver without this field will result in:</p> <pre><code>ValueError: Missing required config for AzureOpenAIModelDriver: azure_endpoint\n</code></pre>"},{"location":"llm-drivers-required-config/#extending-to-other-drivers","title":"Extending to Other Drivers","text":"<p>Other drivers may declare their own required fields (e.g., project_id, base_url) by providing a <code>required_config</code> class attribute as a set or list of key names.</p> <p>This pattern promotes robust, explicitly validated configuration for LLM drivers.</p>"},{"location":"llm-drivers/","title":"LLM Drivers Architecture","text":""},{"location":"llm-drivers/#overview","title":"Overview","text":"<p>The driver layer described below is intended to provide a unified, event-driven interface for interacting with various Large Language Model (LLM) providers (such as OpenAI, Google Gemini, etc.). However, as of this writing, the actual driver code (including the LLMDriver base class and its subclasses) is not present in this directory. The following describes the intended architecture and requirements, but no implementation is currently available here.</p>"},{"location":"llm-drivers/#key-concepts","title":"Key Concepts","text":""},{"location":"llm-drivers/#streaming-event-driven-interface","title":"Streaming, Event-Driven Interface","text":"<ul> <li>All drivers now use a threaded, queue-based input/output mechanism. The agent sends DriverInput objects to the input queue and reads aggregate DriverEvent objects (notably <code>ResponseReceived</code>) from the output queue.</li> <li>Drivers emit standardized events (e.g., <code>ResponseReceived</code>, <code>GenerationStarted</code>, <code>RequestFinished</code>, etc.) as the generation progresses. <code>RequestFinished</code> covers both success, error, and cancellation cases.</li> <li>The new <code>ResponseReceived</code> event contains all content, tool calls, and metadata for that turn, so consumers and agents can react more intelligently (especially for automatic tool invocation patterns).</li> </ul>"},{"location":"llm-drivers/#threading-and-cancellation","title":"Threading and Cancellation","text":"<ul> <li>The generation process runs in a background thread, ensuring that the main application/UI remains responsive.</li> <li>Cooperative cancellation is supported via a <code>threading.Event</code> passed to <code>stream_generate()</code>. Consumers can set this event to abort generation early.</li> <li>Once cancellation is received (i.e., the event is set), drivers will not execute any new tools or send any new requests to the LLM provider. Ongoing operations will be stopped as soon as possible, ensuring prompt and safe cancellation.</li> </ul>"},{"location":"llm-drivers/#consistency-and-extensibility","title":"Consistency and Extensibility","text":"<ul> <li>All drivers inherit from the <code>LLMDriver</code> abstract base class and follow the same event and threading conventions.</li> <li>Each driver handles provider-specific API calls, tool/function execution, and event emission internally, but always exposes the same external interface.</li> </ul>"},{"location":"llm-drivers/#example-usage","title":"Example Usage","text":"<pre><code>import threading\nfrom janito.driver_events import ResponseReceived, RequestFinished\n\ncancel_event = threading.Event()\nfor event in agent.chat(\n    prompt=\"Tell me a joke.\",\n    system_prompt=\"You are a witty assistant.\",\n    cancel_event=cancel_event\n):\n    if isinstance(event, ResponseReceived):\n        for part in event.content_parts:\n            print(part, end=\"\", flush=True)\n    elif isinstance(event, RequestFinished) and getattr(event, 'status', None) == 'error':\n        print(f\"\\n[Error: {event.error}]\")\n</code></pre>"},{"location":"llm-drivers/#supported-events","title":"Supported Events","text":"<ul> <li><code>ResponseReceived</code>: Aggregate response event containing all content parts, all tool calls, and associated metadata for the turn. The agent now listens for this event by default.</li> <li><code>GenerationStarted</code>: Generation process has begun.</li> <li><code>RequestStarted</code>, <code>RequestFinished</code>: API request lifecycle events. <code>RequestFinished</code> includes a <code>status</code> field which may be 'success', 'error', or 'cancelled'.</li> <li>(Legacy granular events such as <code>ContentPartFound</code> are no longer emitted by compliant drivers.)</li> <li>(Provider-specific events may also be emitted.)</li> </ul>"},{"location":"llm-drivers/#adding-a-new-driver","title":"Adding a New Driver","text":"<p>To add support for a new LLM provider:</p> <ol> <li>Subclass <code>LLMDriver</code>.</li> <li>Implement the <code>_process_driver_input()</code> method, which consumes a DriverInput object, performs LLM generation, and emits DriverEvent objects to the output queue.</li> <li>Emit standardized events as output is generated.</li> </ol>"},{"location":"llm-drivers/#provider-specific-notes","title":"Provider-Specific Notes","text":""},{"location":"llm-drivers/#google-gemini-genai-driver","title":"Google Gemini (genai) Driver","text":"<p>The Google Gemini driver (and all other modern drivers) now emits a single <code>ResponseReceived</code> event per turn, which includes both all content parts and all tool/function calls as parsed from the Gemini API response. Downstream consumers and the agent itself inspect the order and content of these lists to reproduce the true conversational order and context, enabling seamless advanced tool execution. No more per-part events if the driver is up-to-date.</p>"},{"location":"llm-drivers/#design-philosophy","title":"Design Philosophy","text":"<ul> <li>Responsiveness: All generation is non-blocking and can be cancelled at any time.</li> <li>Observability: Consumers can react to fine-grained events for real-time UIs, logging, or chaining.</li> <li>Simplicity: A single, modern interface for all drivers.</li> </ul>"},{"location":"moonshotai-setup/","title":"Configuring Janito for MoonshotAI","text":"<p>Janito supports MoonshotAI as an LLM provider. This guide explains how to configure Janito to use MoonshotAI models.</p>"},{"location":"moonshotai-setup/#1-obtain-a-moonshotai-api-key","title":"1. Obtain a MoonshotAI API Key","text":"<ul> <li>Sign up or log in at Moonshot AI Platform to get your API key.</li> <li>Navigate to the API Keys section in your dashboard to create and manage your keys.</li> </ul>"},{"location":"moonshotai-setup/#2-set-your-moonshotai-api-key-in-janito","title":"2. Set Your MoonshotAI API Key in Janito","text":"<p>You must specify both the API key and the provider name when configuring Janito for MoonshotAI:</p> <pre><code>janito --set-api-key YOUR_MOONSHOT_API_KEY -p moonshotai\n</code></pre> <p>Replace <code>YOUR_MOONSHOT_API_KEY</code> with your actual MoonshotAI API key.</p>"},{"location":"moonshotai-setup/#3-select-moonshotai-as-the-provider","title":"3. Select MoonshotAI as the Provider","text":"<p>You can set MoonshotAI as your default provider:</p> <pre><code>janito --set provider=moonshotai\n</code></pre> <p>Or specify it per command:</p> <pre><code>janito -p moonshotai \"Your prompt here\"\n</code></pre>"},{"location":"moonshotai-setup/#4-choose-a-moonshotai-model","title":"4. Choose a MoonshotAI Model","text":"<p>Janito supports the following MoonshotAI models:</p> <ul> <li><code>kimi-k2-turbo-preview</code> (default) - Advanced reasoning model with 128k context window</li> <li><code>kimi-k2-turbo-preview</code> - Turbo version of the advanced reasoning model with 128k context window</li> <li><code>kimi-k1-8k</code> - Standard model with 8k context window</li> <li><code>kimi-k1-32k</code> - Standard model with 32k context window</li> <li><code>kimi-k1-128k</code> - Standard model with 128k context window</li> </ul> <p>To select a model:</p> <pre><code>janito -p moonshotai -m kimi-k1-32k \"Your prompt here\"\n</code></pre>"},{"location":"moonshotai-setup/#5-verify-your-configuration","title":"5. Verify Your Configuration","text":"<p>Show your current configuration (the config file path will be shown at the top):</p> <pre><code>janito --show-config\n</code></pre>"},{"location":"moonshotai-setup/#6-api-endpoint-information","title":"6. API Endpoint Information","text":"<p>MoonshotAI uses an OpenAI-compatible API endpoint:</p> <ul> <li>Base URL: <code>https://api.moonshot.ai/v1</code></li> <li>Authentication: Bearer token (API key)</li> <li>Format: OpenAI API format</li> </ul>"},{"location":"moonshotai-setup/#7-troubleshooting","title":"7. Troubleshooting","text":"<ul> <li>Ensure your API key is correct and has sufficient credits.</li> <li>If you encounter issues, use <code>janito --list-providers</code> to verify MoonshotAI is available.</li> <li>Check your API key permissions and rate limits in the Moonshot AI Platform dashboard.</li> <li>For more help, see the main Configuration Guide or run <code>janito --help</code>.</li> </ul> <p>For more details on supported models and features, see Supported Providers &amp; Models.</p>"},{"location":"openai-setup/","title":"OpenAI Setup Guide","text":"<p>This guide will help you set up Janito to work with OpenAI's models.</p>"},{"location":"openai-setup/#prerequisites","title":"Prerequisites","text":"<ol> <li>An OpenAI account</li> <li>An API key from OpenAI</li> </ol>"},{"location":"openai-setup/#getting-an-api-key","title":"Getting an API Key","text":"<ol> <li>Go to OpenAI's API Keys page</li> <li>Sign in to your OpenAI account</li> <li>Click on \"Create new secret key\"</li> <li>Copy the generated key and save it in a secure location</li> </ol>"},{"location":"openai-setup/#configuration","title":"Configuration","text":"<p>You can configure your OpenAI API key in several ways:</p>"},{"location":"openai-setup/#option-1-using-the-cli","title":"Option 1: Using the CLI","text":"<pre><code>janito --set-api-key openai YOUR_API_KEY\n</code></pre>"},{"location":"openai-setup/#option-2-environment-variable","title":"Option 2: Environment Variable","text":"<p>Set the <code>OPENAI_API_KEY</code> environment variable:</p> <pre><code>export OPENAI_API_KEY=YOUR_API_KEY\n</code></pre> <p>On Windows:</p> <pre><code>set OPENAI_API_KEY=YOUR_API_KEY\n</code></pre>"},{"location":"openai-setup/#option-3-configuration-file","title":"Option 3: Configuration File","text":"<p>Add the following to your Janito configuration file:</p> <pre><code>providers:\n  openai:\n    api_key: YOUR_API_KEY\n</code></pre>"},{"location":"openai-setup/#available-models","title":"Available Models","text":"<p>Janito supports the following OpenAI models:</p> <ul> <li>GPT-5 (default)</li> <li>GPT-5 Mini</li> <li>GPT-5 Nano</li> <li>GPT-4</li> <li>GPT-4 Turbo</li> <li>GPT-3.5 Turbo</li> </ul>"},{"location":"openai-setup/#usage","title":"Usage","text":"<p>After configuration, you can use OpenAI models with Janito:</p> <pre><code># Use the default model (GPT-5)\njanito \"Explain quantum computing\"\n\n# Specify a specific model\njanito -m gpt-4 \"Explain quantum computing\"\n\n# Use in chat mode\njanito -c\n\n# Use in chat mode with a specific model\njanito -c -m gpt-4-turbo\n</code></pre>"},{"location":"openai-setup/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues:</p> <ol> <li>Verify your API key is correct and active</li> <li>Check that you have sufficient credits in your OpenAI account</li> <li>Ensure your network connection can reach OpenAI's API endpoints</li> </ol>"},{"location":"security/","title":"Path Security in Janito","text":"<p>Janito enforces path security for all file and directory arguments passed to tools. This is designed to prevent accidental or malicious access to files outside the intended working directory.</p>"},{"location":"security/#how-path-security-works","title":"How Path Security Works","text":"<ul> <li>By default, any tool argument that looks like a file or directory path is checked to ensure it is within the allowed working directory (<code>workdir</code>).</li> <li>If a path is outside the allowed <code>workdir</code>, the operation is blocked and a security error is raised.</li> <li>This enforcement is automatic for all tools executed via the tools adapter if a <code>workdir</code> is set.</li> </ul>"},{"location":"security/#disabling-path-security","title":"Disabling Path Security","text":"<p>You can disable this restriction using the <code>-u</code> or <code>--unrestricted-paths</code> CLI flag. Disabling path security is dangerous and should only be done if you trust your prompt, tools, and environment.</p> <pre><code>janito -u \"Do something with C:/Windows/System32/hosts\"\n</code></pre> <ul> <li>When path security is disabled, tools can access any file or directory path, including sensitive system files.</li> <li>Only use this option for trusted workflows or debugging.</li> </ul>"},{"location":"security/#example","title":"Example","text":"<p>If <code>workdir</code> is <code>/home/user/project</code> and a tool is called with <code>{ \"path\": \"/etc/passwd\" }</code>, the call will be rejected unless <code>-u</code> is specified.</p>"},{"location":"security/#implementation-details","title":"Implementation Details","text":"<ul> <li>Path security is implemented in <code>janito/tools/path_security.py</code> and integrated in the tools adapter.</li> <li>See the Developer Guide for more technical details.</li> </ul>"},{"location":"security/#see-also","title":"See Also","text":"<ul> <li>CLI Options</li> <li>Tools Developer Guide</li> </ul>"},{"location":"supported-providers-models/","title":"Supported Providers and Models","text":"<p>This page lists the supported providers and their available models, organized by openness and sorted alphabetically within each category.</p>"},{"location":"supported-providers-models/#open-source-open-weight-models","title":"Open-Source / Open-Weight Models","text":""},{"location":"supported-providers-models/#alibaba","title":"Alibaba","text":"<ul> <li>Qwen3 235B A22B Instruct (default) - Latest 1M context model</li> <li>Qwen3 235B A22B Thinking - Reasoning-focused version</li> <li>Qwen3 30B A3B Instruct - Compact 1M context model</li> <li>Qwen3 30B A3B Thinking - Compact reasoning version</li> <li>Qwen3 Coder Plus - Specialized for programming tasks</li> <li>Qwen3 Coder 480B - Large-scale coding model</li> <li>Qwen Turbo - High-speed general purpose</li> <li>Qwen Plus - Balanced performance</li> <li>Qwen Max - Maximum capability</li> </ul>"},{"location":"supported-providers-models/#cerebras","title":"Cerebras","text":"<p>Production Models:</p> <ul> <li>Qwen-3 32B - General instruction following</li> </ul> <p>Preview Models:</p> <ul> <li>Qwen-3 Coder 480B - Programming-focused with 32k context</li> <li>Qwen-3 235B A22B Instruct - Large-scale instruction model</li> <li>Qwen-3 235B A22B Thinking - Reasoning-focused version</li> <li>GPT-OSS 120B - Open-source model</li> </ul> <p>Notes:</p> <ul> <li>All Cerebras models support 128k context window</li> <li>Models are optimized for low-latency inference</li> <li>Pricing varies by model size and capability</li> </ul>"},{"location":"supported-providers-models/#deepseek","title":"DeepSeek","text":"<ul> <li>DeepSeek Chat (default) - General purpose chat model</li> <li>DeepSeek Reasoner - Specialized for complex reasoning tasks</li> </ul>"},{"location":"supported-providers-models/#moonshotai","title":"MoonshotAI","text":"<ul> <li>Kimi K2 Turbo Preview (default) - Latest generation with enhanced performance</li> <li>Kimi K2 0711 Preview - Previous preview version</li> </ul> <p>MoonshotAI provides open-source Kimi models with competitive performance.</p>"},{"location":"supported-providers-models/#zai","title":"Z.AI","text":"<ul> <li>GLM-4.5 (default) - Advanced reasoning and conversation</li> <li>GLM-4.5 Air - Compact and efficient version</li> </ul>"},{"location":"supported-providers-models/#proprietary-models","title":"Proprietary Models","text":""},{"location":"supported-providers-models/#anthropic","title":"Anthropic","text":"<ul> <li>Claude 3.7 Sonnet (default) - Latest Claude model with enhanced reasoning</li> <li>Claude 4 Opus - Most capable Claude model (preview)</li> <li>Claude 4 Sonnet - Balanced performance and capability (preview)</li> <li>Claude 3.5 Sonnet - Previous generation, still highly capable</li> <li>Claude 3.5 Haiku - Fast and efficient</li> <li>Claude 3 Haiku - Compact and cost-effective</li> </ul>"},{"location":"supported-providers-models/#google","title":"Google","text":"<ul> <li>Gemini 2.5 Flash (default) - Fast and efficient</li> <li>Gemini 2.5 Pro - Advanced capabilities with extended context</li> <li>Gemini 2.5 Flash-Lite Preview - Lightweight preview version</li> </ul>"},{"location":"supported-providers-models/#openai","title":"OpenAI","text":"<ul> <li>GPT-5 (default) - Latest generation with advanced reasoning</li> <li>GPT-5 Mini - Compact version of GPT-5</li> <li>GPT-5 Nano - Ultra-compact version</li> <li>GPT-4.1 - Enhanced GPT-4 with improved capabilities</li> <li>GPT-4.1-mini - Balanced performance and efficiency</li> <li>GPT-4.1-nano - Lightweight version</li> <li>GPT-4 Turbo - High-performance GPT-4 variant</li> <li>GPT-4o - Multimodal GPT-4 optimized for chat</li> <li>GPT-4o-mini - Compact multimodal version</li> <li>o3 - Advanced reasoning model</li> <li>o3-mini - Compact reasoning model</li> <li>o4-mini - Latest mini reasoning model</li> <li>GPT-3.5 Turbo - Cost-effective general purpose</li> </ul> <p>For setup instructions, see the OpenAI Setup Guide.</p>"},{"location":"supported-providers-models/#azure-openai","title":"Azure OpenAI","text":"<ul> <li>Azure OpenAI Deployment - Custom Azure OpenAI deployments</li> </ul> <p>For setup instructions, see Using Azure OpenAI with Janito.</p>"},{"location":"tools-index/","title":"Tools Index","text":"<p>Janito provides a comprehensive set of tools for file operations, code execution, web access, and more. Tools can be selectively disabled using the disabled tools configuration.</p>"},{"location":"tools-index/#available-tools","title":"Available Tools","text":""},{"location":"tools-index/#web-tools","title":"Web Tools","text":""},{"location":"tools-index/#open_url","title":"open_url","text":"<p>Opens the supplied URL or local file in the default web browser.</p> <p>Arguments:</p> <ul> <li><code>url</code> (str): The URL or local file path (as a file:// URL) to open. Supports both web URLs (http, https) and local files (file://).</li> </ul> <p>Returns:</p> <ul> <li>Status message indicating the result.</li> </ul> <p>Example Usage:</p> <ul> <li>Open a website: <code>open_url(url=\"https://example.com\")</code></li> <li>Open a local file: <code>open_url(url=\"file:///C:/path/to/file.html\")</code></li> </ul> <p>This tool replaces the previous <code>open_html_in_browser</code> tool, and can be used for both web and local files.</p>"},{"location":"tools-index/#search_text","title":"search_text","text":"<p>Search for a text query in files or directories.</p> <p>Arguments:</p> <ul> <li><code>paths</code> (str): Space-separated list of file or directory paths to search in.</li> <li><code>query</code> (str): Text or regular expression to search for.</li> <li><code>use_regex</code> (bool): Treat <code>query</code> as a regex pattern (default: False).</li> <li><code>case_sensitive</code> (bool): Enable case-sensitive search (default: False).</li> <li><code>max_depth</code> (int): Maximum directory depth to search (default: 0 = unlimited).</li> <li><code>max_results</code> (int): Maximum matching lines to return (default: 100).</li> <li><code>count_only</code> (bool): Return only match counts instead of lines (default: False).</li> </ul> <p>Returns:</p> <ul> <li>Matching lines with file paths and line numbers, or match counts if <code>count_only=True</code>.</li> </ul> <p>Example Usage:</p> <ul> <li>Plain-text search: <code>search_text(paths=\"src\", query=\"TODO\")</code></li> <li>Regex search: <code>search_text(paths=\"src tests\", query=r\"def\\s+\\w+\", use_regex=True)</code></li> <li>Case-insensitive count: <code>search_text(paths=\"docs\", query=\"janito\", case_sensitive=False, count_only=True)</code></li> </ul>"},{"location":"tools-index/#tool-management","title":"Tool Management","text":""},{"location":"tools-index/#disabling-tools","title":"Disabling Tools","text":"<p>You can disable specific tools using configuration:</p> <pre><code># Disable interactive prompts\njanito --set disabled_tools=ask_user\n\n# Disable code execution\njanito --set disabled_tools=python_code_run,run_powershell_command\n\n# View current disabled tools and config file path\njanito --show-config\n</code></pre>"},{"location":"tools-index/#listing-available-tools","title":"Listing Available Tools","text":"<p>See all currently available tools:</p> <pre><code>janito --list-tools\n</code></pre> <p>For complete documentation on tool disabling, see the Disabling Tools Guide.</p>"},{"location":"tools-natural-results/","title":"Natural Results: Human-Friendly Output from Janito Tools","text":""},{"location":"tools-natural-results/#why-janito-tools-use-unstructured-line-based-output","title":"Why Janito Tools Use Unstructured, Line-Based Output","text":"<p>Janito's tools are designed to provide results in a natural, unstructured, line-based format\u2014the same style commonly found in code examples, tutorials, and instructional materials. This approach is intentional and is based on several key considerations:</p>"},{"location":"tools-natural-results/#1-familiarity-and-clarity","title":"1. Familiarity and Clarity","text":"<ul> <li>Most developers are accustomed to reading and understanding code in its natural, unannotated form. Code examples, documentation, and learning resources rarely use diff formats; instead, they present the code as it should appear after edits.</li> <li>By outputting results in this familiar format, Janito ensures that users can quickly understand and apply the changes without needing to mentally parse diff markers or context lines.</li> </ul>"},{"location":"tools-natural-results/#2-avoiding-out-of-context-patterns","title":"2. Avoiding Out-of-Context Patterns","text":"<ul> <li>Diff-based formats (such as unified diffs with <code>+</code>, <code>-</code>, or <code>@@</code> markers) are excellent for code review and version control, but they introduce artificial patterns and symbols that are not part of the actual code.</li> <li>When these patterns are present in the editing or code generation flow, they can inadvertently influence the language model or the user's perception, potentially leading to lower-quality code or confusion.</li> <li>Janito optimizes for clean, context-free code generation, reducing the risk of such artifacts affecting the output.</li> </ul>"},{"location":"tools-natural-results/#3-optimized-for-human-editing","title":"3. Optimized for Human Editing","text":"<ul> <li>The primary goal of Janito's output is to facilitate smooth, human-friendly editing. Users can copy, paste, and apply changes directly, just as they would with code snippets from trusted documentation.</li> <li>This approach streamlines the workflow for developers who want to quickly update their codebase without extra processing or translation steps.</li> </ul>"},{"location":"tools-natural-results/#4-review-remains-easy-with-standard-tools","title":"4. Review Remains Easy with Standard Tools","text":"<ul> <li>While Janito does not output diffs directly, users can still perform thorough code reviews using standard version control tools (like <code>git diff</code>) after applying the changes.</li> <li>This separation of concerns ensures that code generation and review are both optimized for their respective contexts: natural output for editing, and diff-based tools for review.</li> </ul>"},{"location":"tools-natural-results/#summary","title":"Summary","text":"<p>Janito's natural, line-based output format is designed to:</p> <ul> <li>Maximize clarity and usability for developers.</li> <li>Avoid introducing out-of-context patterns that could degrade code quality.</li> <li>Support efficient, human-friendly editing flows.</li> <li>Allow for robust reviews using existing diff tools after changes are applied.</li> </ul> <p>This philosophy ensures that Janito remains a seamless, developer-centric assistant\u2014helping you write, edit, and improve code in the most natural way possible.</p>"},{"location":"tools-precision/","title":"Precision in Context Construction: Outlines, Search, and Token Optimization","text":"<p>Large Language Models (LLMs) like those used in Janito are powerful, but their effectiveness depends heavily on the quality and relevance of the context provided to them. Precision in context construction is crucial for:</p> <ul> <li>Improving the model\u2019s attention and accuracy.</li> <li>Reducing irrelevant information (noise).</li> <li>Optimizing the use of available tokens (which are limited per request).</li> </ul>"},{"location":"tools-precision/#why-precision-matters","title":"Why Precision Matters","text":"<p>LLMs have a fixed token limit for each prompt. Supplying too much irrelevant or excessive context can:</p> <ul> <li>Waste valuable tokens.</li> <li>Dilute the model\u2019s focus, leading to less accurate or less relevant responses.</li> </ul> <p>By contrast, providing only the most relevant code, documentation, or data enables the LLM to:</p> <ul> <li>Focus its attention on what matters for the current task.</li> <li>Produce more accurate, actionable, and context-aware outputs.</li> </ul>"},{"location":"tools-precision/#how-janito-achieves-precision","title":"How Janito Achieves Precision","text":"<p>Janito uses a combination of outline and search utilities to extract only the most relevant portions of code or documentation:</p>"},{"location":"tools-precision/#1-outline-utilities","title":"1. Outline Utilities","text":"<ul> <li>Purpose: Quickly analyze the structure of files (e.g., Python modules, Markdown docs) to identify classes, functions, methods, headers, and sections.</li> <li>How it works:</li> <li>The outline tool parses the file and builds a map of its structure.</li> <li>This enables Janito to select specific ranges (e.g., a single function, class, or section) rather than the entire file.</li> <li>Benefits:</li> <li>Enables targeted extraction.</li> <li>Reduces the amount of irrelevant context.</li> </ul>"},{"location":"tools-precision/#2-search-utilities","title":"2. Search Utilities","text":"<ul> <li>Purpose: Find precise locations of keywords, function names, class names, or documentation headers within files or across the project.</li> <li>How it works:</li> <li>The search tool can use substring or regex matching to locate relevant lines or blocks.</li> <li>Results are mapped to file ranges or outline nodes, allowing for precise extraction.</li> <li>Benefits:</li> <li>Supports both broad and fine-grained queries.</li> <li>Can be combined with outline data for even more accurate targeting.</li> </ul>"},{"location":"tools-precision/#building-tailored-contexts","title":"Building Tailored Contexts","text":"<p>When Janito receives a request (e.g., \"Refactor function X\" or \"Summarize section Y\"), it:</p> <ol> <li>Uses outline and search tools to locate the exact code or documentation range relevant to the task.</li> <li>Extracts only that range (plus minimal necessary context, such as imports or docstrings).</li> <li>Constructs the LLM prompt using just the tailored content, not the entire file or project.</li> </ol>"},{"location":"tools-precision/#benefits-for-llm-attention-and-token-efficiency","title":"Benefits for LLM Attention and Token Efficiency","text":"<ul> <li>Improved Attention: The LLM can focus on the most relevant code or documentation, leading to better understanding and more accurate results.</li> <li>Token Optimization: By sending only what\u2019s needed, Janito avoids hitting token limits and can handle larger projects or more complex tasks within the same constraints.</li> <li>Faster, More Relevant Responses: Less noise means the model can reason more effectively and respond more quickly.</li> </ul>"},{"location":"tools-precision/#summary","title":"Summary","text":"<p>Janito\u2019s precision-driven approach\u2014using outline and search utilities to extract and assemble only the most relevant context\u2014maximizes the effectiveness of LLMs. This ensures:</p> <ul> <li>Higher quality answers.</li> <li>Better use of computational resources.</li> <li>A more scalable and robust developer experience.</li> </ul>"},{"location":"z-ai-setup/","title":"Z.ai API Setup Guide","text":"<p>This guide explains how to set up and use Z.ai's API with your API key.</p>"},{"location":"z-ai-setup/#getting-your-api-key","title":"Getting Your API Key","text":"<ol> <li>Visit Z.ai API Management</li> <li>Log in to your Z.ai account</li> <li>Navigate to the API Keys section</li> <li>Create a new API key if you don't have one yet</li> </ol>"},{"location":"z-ai-setup/#api-key-format","title":"API Key Format","text":"<p>Z.ai uses a new key format that includes both a user ID and secret:</p> <pre><code>{id}.{secret}\n</code></pre> <p>Important Security Notes:</p> <ul> <li>Never share your API keys</li> <li>Do not expose keys in browsers or client-side code</li> <li>Leaked keys may be automatically regenerated for security</li> <li>Store keys securely in environment variables or secure vaults</li> </ul>"},{"location":"z-ai-setup/#setting-up-your-environment","title":"Setting Up Your Environment","text":""},{"location":"z-ai-setup/#environment-variable-recommended","title":"Environment Variable (Recommended)","text":"<p>Set your API key as an environment variable:</p> <p>Linux/macOS:</p> <pre><code>export ZAI_API_KEY=\"your-id.your-secret\"\n</code></pre> <p>Windows (Command Prompt):</p> <pre><code>set ZAI_API_KEY=your-id.your-secret\n</code></pre> <p>Windows (PowerShell):</p> <pre><code>$env:ZAI_API_KEY=\"your-id.your-secret\"\n</code></pre>"},{"location":"z-ai-setup/#configuration-file","title":"Configuration File","text":"<p>You can also store your API key in a configuration file (ensure proper file permissions):</p> <pre><code>{\n  \"zai_api_key\": \"your-id.your-secret\"\n}\n</code></pre>"},{"location":"z-ai-setup/#rate-limits-and-billing","title":"Rate Limits and Billing","text":"<ul> <li>Check your API Management dashboard for current rate limits</li> <li>Monitor your usage and billing information</li> <li>Contact support for API recharge if needed</li> </ul>"},{"location":"z-ai-setup/#support","title":"Support","text":"<p>For API-related support:</p> <ul> <li>Visit Z.ai Contact for product support</li> <li>Join the Discord community to chat with developers</li> <li>Check the API documentation for model-specific details</li> </ul>"},{"location":"z-ai-setup/#available-models","title":"Available Models","text":"<p>Z.ai provides several models including:</p> <ul> <li>GLM-4.5: Latest flagship model with reasoning, coding, and agent functionalities</li> <li>GLM-4.5-Air: Lightweight flagship model with cost-effectiveness</li> <li>GLM-4.5-Flash: Most advanced free model</li> <li>GLM-4-32B-0414-128K: General-purpose LLM for business and technical domains</li> <li>CogVideoX-3: Text-to-video model for high-fidelity motion</li> <li>Vidu Q1: High-fidelity 1080p video generation</li> <li>Vidu 2: Fast, low-cost 720p video generation</li> </ul> <p>For complete model specifications and capabilities, visit Z.ai Models.</p>"},{"location":"about/costs/","title":"\ud83d\udcb8 Costs &amp; Value Transparency","text":""},{"location":"about/costs/#how-janito-handles-costs","title":"\ud83d\udca1 How Janito Handles Costs","text":"<ul> <li>\ud83c\udd93 No Extra Fees: Janito is open source and does not charge any additional fees for usage.</li> <li>\ud83d\udd11 Bring Your Own API Key: By default, Janito uses OpenAI, but you can also connect your own Azure or compatible API key. You pay only for what you use, directly to the provider.</li> <li>\ud83d\udc40 Full Visibility: You can monitor your API usage and costs through your provider\u2019s dashboard, with no hidden markups.</li> </ul>"},{"location":"about/costs/#comparison-subscription-models-in-other-tools","title":"\ud83d\udd04 Comparison: Subscription Models in Other Tools","text":"<ul> <li>\u2705 Costs Under Control: Subscription models can help users predict their monthly expenses, providing cost certainty regardless of usage spikes.</li> <li>\ud83d\udcb3 Flat Monthly Fees: Many AI coding assistants or IDE plugins charge a monthly subscription, regardless of how much you use them.</li> <li>\ud83d\udd73\ufe0f Opaque Value: These tools manage the context, prompts, and API usage behind the scenes. You don\u2019t know how much of your subscription is spent on actual model calls versus overhead or unused features.</li> <li>\ud83d\udeab Limited Control: You can\u2019t tune the context window, prompt, or tool usage to optimize for cost or value.</li> </ul>"},{"location":"about/costs/#context-optimization-and-token-efficiency","title":"\ud83e\udde0 Context Optimization and Token Efficiency","text":"<ul> <li>\ud83e\udde9 Smart Context Selection: Janito\u2019s tools are designed to select only the most relevant files, code snippets, or configuration details for each request, based on your prompt and intent.</li> <li>\ud83c\udfaf Aligned with Your Goals: Instead of sending your entire project or irrelevant data, Janito tailors the context to what you actually need\u2014whether that\u2019s UI, backend, or documentation.</li> <li>\ud83d\udcb0 Token Usage Efficiency: By minimizing unnecessary context, Janito helps you get more value from each API call, reducing token usage and cost while maximizing the quality of responses.</li> </ul>"},{"location":"about/costs/#janitos-advantage-cost-transparency","title":"\ud83d\udd0d Janito\u2019s Advantage: Cost Transparency","text":"<ul> <li>\ud83d\udcb8 Pay for What You Use: Every API call is under your control. You decide when and how to use the model, and can optimize prompts or tool usage for efficiency.</li> <li>\ud83d\udeab No Hidden Usage: There\u2019s no \u201cblack box\u201d between you and the model\u2014no risk of surprise overages or wasted spend.</li> <li>\ud83c\udfaf Direct Value: You see exactly how your usage translates to results, and can adjust your workflow to maximize value for your spend.</li> </ul>"},{"location":"about/costs/#summary","title":"\ud83c\udfc1 Summary","text":"<p>With Janito, you\u2019re in control: no subscriptions, no hidden fees, and full transparency into how your costs deliver value.</p>"},{"location":"about/vs-webchats/","title":"\ud83d\udcac Janito vs. Web-Based AI Chats","text":"<p>While web-based AI chats (like ChatGPT, Gemini, or Copilot web) are popular for code help, Janito offers significant advantages for project analysis and automation:</p>"},{"location":"about/vs-webchats/#overhead-of-manual-copypaste","title":"\u23f3 Overhead of Manual Copy/Paste","text":"<ul> <li>\ud83d\udd52 Time-Consuming: Copying large files, code snippets, or project structures into a web chat is slow and repetitive.</li> <li>\ud83d\udd0d Context Loss: Web chats lack awareness of your full project structure, dependencies, and configuration.</li> <li>\u26a0\ufe0f Error-Prone: Manual copy/paste increases the risk of missing files, truncating code, or introducing formatting errors.</li> <li>\ud83d\udeab No Automation: Each session is isolated; you can\u2019t script or automate workflows across your project.</li> </ul>"},{"location":"about/vs-webchats/#risks-to-accuracy-and-privacy","title":"\ud83d\udd12 Risks to Accuracy and Privacy","text":"<ul> <li>\u274c Incomplete Analysis: Web chats only see what you paste, missing important context or related files.</li> <li>\ud83e\uddd1\u200d\ud83d\udcbb Human Error: It\u2019s easy to accidentally omit, duplicate, or mislabel code when copying manually.</li> <li>\ud83d\udd75\ufe0f\u200d\u2642\ufe0f Privacy Concerns: Pasting proprietary code into a third-party web service may violate company policy or expose sensitive information.</li> </ul>"},{"location":"about/vs-webchats/#janitos-advantages","title":"\ud83c\udfc6 Janito\u2019s Advantages","text":"<ul> <li>\ud83d\udcc2 Direct Project Access: Janito can analyze your entire codebase, follow imports, and reference configuration automatically.</li> <li>\ud83d\udd01 Repeatable &amp; Scriptable: Automate reviews, refactoring, or documentation with CLI commands and scripts.</li> <li>\ud83e\udde0 Rich Context: Tools and prompts can be tailored to your workflow, ensuring the AI sees the right context every time.</li> <li>\u2702\ufe0f No Copy/Paste Needed: Save time and reduce mistakes by working directly with your files.</li> </ul>"},{"location":"about/vs-webchats/#summary","title":"\ud83c\udfc1 Summary","text":"<p>Janito eliminates the friction, risk, and limitations of manual copy/paste into web chats\u2014delivering faster, more accurate, and more secure project assistance.</p>"},{"location":"about/why/","title":"\u2753 Why Janito? The Power of Prompt and Tool Flexibility","text":"<p>Janito is designed to give you maximum control over how AI assists you with your codebase. Unlike tools tightly coupled with a specific IDE, Janito\u2019s flexible system prompt and tool configuration offer unique advantages:</p>"},{"location":"about/why/#benefits-of-adjustable-system-prompts","title":"\ud83c\udfaf Benefits of Adjustable System Prompts","text":"<ul> <li>\ud83d\udcdd Tailor the Assistant\u2019s Perspective: By editing the system prompt, you can instruct the AI to focus on what matters most\u2014UI/UX, backend logic, architecture, or even documentation style.</li> <li>\ud83d\udd04 Adapt to Different Tasks: Switch between reviewing code for bugs, generating documentation, or brainstorming features simply by changing the prompt.</li> <li>\ud83d\udc40 Guide the Model\u2019s Focus: A prompt like \u201cYou are a UI/UX expert\u201d will make the model prioritize interface concerns, while \u201cFocus on code structure and algorithms\u201d will drive it to analyze raw code logic.</li> </ul>"},{"location":"about/why/#flexible-tools-vs-ide-coupled-plugins","title":"\ud83e\udde9 Flexible Tools vs. IDE-Coupled Plugins","text":"<ul> <li>\ud83d\udcbb Not Locked to an Editor: Janito works in the terminal, scripts, or web\u2014no need for a heavyweight IDE or plugin ecosystem.</li> <li>\ud83e\uddf0 Composable and Extensible: Tools can be enabled, disabled, or customized for each session, letting you experiment or automate workflows.</li> <li>\ud83d\udd52 Session-Scoped Adjustments: Temporary overrides (via CLI options or prompt tweaks) let you try new approaches without changing your global setup.</li> </ul>"},{"location":"about/why/#example-prompt-driven-focus","title":"\ud83e\uddd1\u200d\ud83d\udcbb Example: Prompt-Driven Focus","text":"<ul> <li> <p>A prompt like:</p> <p>\u201cYou are a code reviewer. Focus on accessibility and UI clarity.\u201d   will make the model highlight interface and user experience issues.</p> </li> <li> <p>Change the prompt to:</p> <p>\u201cYou are a backend architect. Ignore UI, focus on data flow and performance.\u201d   and the model will shift its analysis accordingly.</p> </li> </ul>"},{"location":"about/why/#summary","title":"\ud83c\udfc1 Summary","text":"<p>Janito\u2019s decoupled, prompt-driven approach empowers you to get the AI help you need, where and how you want it\u2014without being boxed in by IDE limitations or rigid workflows.</p>"},{"location":"code_intelligence/agentic-frameworks-comparison/","title":"Why Janito Uses a Built-in Agentic Framework for Code","text":""},{"location":"code_intelligence/agentic-frameworks-comparison/#overview","title":"Overview","text":"<p>Janito is designed with a built-in agentic framework tailored specifically for code generation, analysis, and editing. This approach is fundamentally different from most general-purpose agentic frameworks, which are typically optimized for structured data extraction and workflow automation.</p>"},{"location":"code_intelligence/agentic-frameworks-comparison/#general-purpose-agentic-frameworks","title":"General-purpose Agentic Frameworks","text":"<ul> <li>Primary Focus:</li> <li>Extracting structured data from unstructured text (e.g., forms, tables, summaries).</li> <li>Automating business processes, information retrieval, or conversational flows.</li> <li>Strengths:</li> <li>Well-suited for tasks where the output is a set of fields, entities, or facts.</li> <li>Often rely on templates, schemas, or predefined extraction rules.</li> <li>Limitations for Code:</li> <li>Lack deep understanding of code semantics, dependencies, and context.</li> <li>Not designed for precise, context-aware code editing or refactoring.</li> <li>Struggle with the fragility and interconnectedness of code (see Challenges of Code Generation and Editing for LLMs).</li> </ul>"},{"location":"code_intelligence/agentic-frameworks-comparison/#janitos-built-in-agentic-framework","title":"Janito\u2019s Built-in Agentic Framework","text":"<ul> <li>Primary Focus:</li> <li>Code search, analysis, editing, and refactoring.</li> <li>Maintaining traceability and explicit error handling.</li> <li>Supporting developer workflows and codebase evolution.</li> <li>Key Features:</li> <li>Step-by-step code search and inference, with user-visible progress (see Code Generation Observability).</li> <li>Validation and testing of code changes.</li> <li>Awareness of code structure, dependencies, and side effects.</li> <li>Designed for iterative, collaborative development.</li> </ul>"},{"location":"code_intelligence/agentic-frameworks-comparison/#why-this-matters","title":"Why This Matters","text":"<ul> <li>Reliability: Code changes require precision and context-awareness\u2014mistakes can break systems.</li> <li>Traceability: Developers need to understand and audit every change, not just the final output.</li> <li>Developer Experience: Janito\u2019s workflow is optimized for real-world coding, not just data extraction.</li> </ul>"},{"location":"code_intelligence/agentic-frameworks-comparison/#conclusion","title":"Conclusion","text":"<p>Janito\u2019s tailored agentic framework is purpose-built for the unique challenges of code generation and editing. It provides the transparency, precision, and control that developers need\u2014going far beyond what general-purpose agentic frameworks can offer for code-centric tasks.</p> <p>generated by janito.dev</p>"},{"location":"code_intelligence/code-generation-challenges/","title":"Challenges of Code Generation and Editing for LLMs","text":"<p>Code Intelligence provides human-in-control intelligence for code understanding, editing, and reliability.</p>"},{"location":"code_intelligence/code-generation-challenges/#what-is-code","title":"What is \"Code\"?","text":"<p>\"Code\" refers to formal instructions written in programming languages. Unlike natural language, code is designed for unambiguous interpretation by machines. Code has strict syntax, grammar, and semantics, and even small deviations can cause errors or unintended behavior.</p>"},{"location":"code_intelligence/code-generation-challenges/#code-semantics-vs-natural-language-semantics","title":"Code Semantics vs. Natural Language Semantics","text":"Aspect Natural Language Code Flexibility Flexible, redundant, context-dependent Precise, rigid, context-sensitive Distribution of Meaning Distributed across words, sentences, and context Concentrated; each token can have a critical role Error Tolerance Minor errors (typos, word swaps) often ignored/understood Small changes (e.g., missing semicolon) can break code Ambiguity Common, resolved by context or intent Not tolerated; requires exactness"},{"location":"code_intelligence/code-generation-challenges/#distribution-and-impact-of-changes","title":"Distribution and Impact of Changes","text":"<ul> <li>Natural Language:</li> <li>Meaning is distributed; a single word rarely changes the entire message.</li> <li>Redundancy allows for graceful degradation\u2014messages are often recoverable.</li> <li> <p>Editing is forgiving; paraphrasing or rewording usually preserves intent.</p> </li> <li> <p>Code:</p> </li> <li>Meaning is concentrated; a single character can change program logic or cause failure.</li> <li>No redundancy\u2014every symbol matters.</li> <li>Editing is fragile; even minor changes can have cascading effects (syntax errors, logic bugs, security vulnerabilities).</li> </ul>"},{"location":"code_intelligence/code-generation-challenges/#challenges-for-llms","title":"Challenges for LLMs","text":"<ol> <li>Syntax Sensitivity:</li> <li>LLMs must generate code that is syntactically valid for the target language.</li> <li> <p>Minor mistakes can render code non-functional.</p> </li> <li> <p>Semantic Precision:</p> </li> <li>LLMs must understand the intent and context to generate correct logic.</li> <li> <p>Misunderstanding requirements can lead to subtle bugs.</p> </li> <li> <p>Context Management:</p> </li> <li>Code often depends on definitions and context spread across files or modules.</li> <li> <p>LLMs must track and respect scope, imports, and dependencies.</p> </li> <li> <p>Refactoring and Editing:</p> </li> <li>Editing code requires understanding dependencies and side effects.</li> <li> <p>LLMs must avoid introducing regressions when making changes.</p> </li> <li> <p>Testing and Validation:</p> </li> <li>Unlike natural language, code must be tested (compiled, run) to verify correctness.</li> <li>LLMs should ideally validate or simulate code execution.</li> </ol>"},{"location":"code_intelligence/code-generation-challenges/#why-these-challenges-matter","title":"Why These Challenges Matter","text":"<ul> <li>Reliability: Small errors can cause major failures in software systems.</li> <li>Safety: Bugs in code can lead to security vulnerabilities or data loss.</li> <li>Collaboration: Code is read and maintained by teams; clarity and correctness are essential.</li> </ul> <p>generated by janito.dev</p>"},{"location":"code_intelligence/code-generation-observability/","title":"Code Generation Observability","text":""},{"location":"code_intelligence/code-generation-observability/#overview","title":"Overview","text":"<p>Code Generation Observability is a feature that provides users with transparent, step-by-step visibility into the assistant's code search, analysis, and generation process. This allows users to:</p> <ul> <li>See which files, lines, and patterns are being searched.</li> <li>Observe the assistant's inference and workflow as it investigates issues or implements features.</li> <li>Intervene or redirect the assistant by providing feedback at each step, improving the quality and relevance of the results.</li> </ul>"},{"location":"code_intelligence/code-generation-observability/#benefits","title":"Benefits","text":"<ul> <li>Transparency: Users understand how results are produced.</li> <li>Debuggability: Easier to spot where misunderstandings or errors occur.</li> <li>Control: Users can guide the assistant more effectively.</li> </ul>"},{"location":"code_intelligence/code-generation-observability/#example-workflow","title":"Example Workflow","text":"<p>When investigating a problem (e.g., a missing keyboard shortcut), the assistant will:</p> <ol> <li>Search for relevant keywords or patterns in the codebase.</li> <li>Display search results, including file names and matching lines.</li> <li>Summarize findings and request user input if multiple directions are possible.</li> <li>Continue investigation or implementation based on user feedback.</li> </ol>"},{"location":"code_intelligence/code-generation-observability/#screenshot","title":"Screenshot","text":"<p>generated by janito.dev</p>"},{"location":"code_intelligence/our-approach/","title":"Our Approach to Code Intelligence and Editing","text":""},{"location":"code_intelligence/our-approach/#overview","title":"Overview","text":"<p>Janito\u2019s approach to code intelligence is designed to maximize transparency, traceability, and user alignment. We leverage methods and primitives that are familiar to developers and closely aligned with human inference and established tooling.</p>"},{"location":"code_intelligence/our-approach/#context-building-with-human-like-primitives","title":"Context Building with Human-like Primitives","text":"<ul> <li>Search Text &amp; Search File:</li> <li>We use explicit text and file search operations to build context, similar to how developers use <code>grep</code>, <code>find</code>, or IDE search.</li> <li>This makes every step visible and auditable, allowing users to understand and guide the assistant\u2019s inference.</li> </ul>"},{"location":"code_intelligence/our-approach/#string-replacement-over-diff","title":"String Replacement over Diff","text":"<ul> <li>Natural Language Alignment:</li> <li>Instead of relying solely on code diffs, we use string replacement primitives.</li> <li>This approach is more aligned with how humans describe changes (\"replace X with Y\"), and is easier to validate and review.</li> <li>It reduces ambiguity and makes the change process more transparent.</li> </ul>"},{"location":"code_intelligence/our-approach/#range-selection-and-contextual-references","title":"Range Selection and Contextual References","text":"<ul> <li>Filename:Line Number:Context:</li> <li>We adopt conventions like <code>filename:line_nr:context</code> for referencing code locations.</li> <li>This is inspired by tools like <code>grep</code> and error reporting systems in Python, JavaScript, and other languages.</li> <li>It enables precise, context-rich navigation and error reporting.</li> </ul>"},{"location":"code_intelligence/our-approach/#benefits-of-our-approach","title":"Benefits of Our Approach","text":"<ul> <li>Transparency: Every step is explicit and visible to the user.</li> <li>Traceability: Changes and inference can be audited and reviewed.</li> <li>User Alignment: Methods are familiar to developers, reducing friction and cognitive load.</li> <li>Reliability: By mirroring established developer workflows, we minimize surprises and errors.</li> </ul> <p>generated by janito.dev</p>"},{"location":"code_intelligence/why-string-replacement/","title":"Why Janito Prefers String\u2011Replacement Rules over Unified Diffs","text":""},{"location":"code_intelligence/why-string-replacement/#overview","title":"Overview","text":"<p>Janito is an LLM\u2011driven code\u2011editing agent. Instead of asking the model to provide a unified diff, Janito provides tooling primitives that steer the model to emit a set of deterministic plain\u2011string find/replace rules, which Janito then applies atomically. This choice maximises reliability, prompt economy, and alignment with the model\u2019s learned behaviour.</p>"},{"location":"code_intelligence/why-string-replacement/#1-trainingsignal-alignment","title":"1  Training\u2011Signal Alignment","text":"<ul> <li>Dominant exposure to raw code. In public\u2011code crawls, plain source lines outnumber diff tokens by ~20\u201140\u202f:\u202f1. The model has far richer \u201cmuscle memory\u201d for patterns like <code>foo(bar)</code> than for hunk headers such as <code>@@ -42,7 +42,8 @@</code>.</li> <li>Micro\u2011edit datasets reinforce replacements. Fine\u2011tune corpora like Google Codediffs and CommitPack present before/after snippets aligned token\u2011by\u2011token. The most common gradient update is \u201csubstitute X with Y,\u201d not \u201cparse and merge a patch.\u201d</li> <li>Pull\u2011request &amp; review corpora add contextual edits. Large crawls ingest GitHub PR diffs, mailing\u2011list patches (e.g., LKML), and Stack\u202fOverflow suggested edits. These sources boost the model\u2019s familiarity with diff syntax, but they remain a minority slice of the overall training mix and are often noisier than pristine source.</li> <li>Forums &amp; step\u2011by\u2011step tutorials reinforce direct replacements. Blog posts and Q&amp;A answers frequently present code \u201cbefore\u201d and \u201cafter,\u201d or instruct: \u201cChange <code>foo = false</code> to <code>foo = true</code> in your config.\u201d These snippets rarely include full diff headers; they mirror the granularity of plain string edits, further tuning the model toward replacement\u2011style transformations.</li> </ul> <p>Implication: A replacement rule asks the model to perform the transformation it has practised millions of times; interpreting a diff asks it to switch to a much rarer skill.</p>"},{"location":"code_intelligence/why-string-replacement/#2-tokenbudget-efficiency","title":"2  Token\u2011Budget Efficiency","text":"Expression of the same change Typical token cost Unified diff (6\u2011line hunk) ~70\u201390 tokens Plain string\u2011replacement rule ~10\u201315 tokens <p>Shorter prompts leave more room for actual code and high\u2011level instructions, reducing context\u2011window pressure and latency.</p>"},{"location":"code_intelligence/why-string-replacement/#3-robustness-in-real-codebases","title":"3  Robustness in Real Codebases","text":"<ul> <li>Line\u2011shift tolerance. If the file drifts after the diff was generated, context lines may no longer match. A string rule keyed to the target pattern still fires.</li> <li>Noise immunity. Email trailers, MIME boundaries, or CI banners embedded in patches confuse parsers but do not affect literal pattern matching.</li> <li>Encoding quirks. Different EOL conventions or charset mishaps break patch offsets; a plain string match usually survives them.</li> </ul>"},{"location":"code_intelligence/why-string-replacement/#takeaway","title":"Takeaway","text":"<p>Plain string\u2011replacement rules line up with the LLM\u2019s most frequent training examples, use a fraction of the tokens, and sidestep brittle patch\u2011parsing failure modes. That is why Janito\u2019s selected edit strategy is rule\u2011first.</p>"},{"location":"concepts/","title":"Concepts &amp; Terminology","text":"<p>This section collects foundational explanations, terminology, and conventions used throughout the documentation. It is intended to help new users and developers understand the key ideas and language model concepts relevant to Janito and similar tools.</p>"},{"location":"concepts/#available-topics","title":"Available Topics","text":"<ul> <li> <p>What Is a Language Model Client?</p> </li> <li> <p>Prompt Analysis Style</p> </li> <li> <p>Prompt Design Style</p> </li> <li> <p>Human-Guided AI Principle</p> </li> </ul> <p>More topics will be added here as the documentation evolves.</p>"},{"location":"concepts/analysis-style/","title":"Analysis Prompting Style: Declaring Role and Knowledge Domain","text":""},{"location":"concepts/analysis-style/#overview","title":"Overview","text":"<p>For effective and reliable AI-driven analysis, prompts should begin by explicitly declaring the intended role and the relevant knowledge domain. This establishes context, sets expectations, and guides the model\u2019s reasoning and language style.</p>"},{"location":"concepts/analysis-style/#why-declare-role-and-domain","title":"Why Declare Role and Domain?","text":"<ul> <li>Role Declaration: Instructs the model to adopt a specific perspective (e.g., software engineer, security auditor, data scientist).</li> <li>Domain Declaration: Focuses the model\u2019s attention on the relevant field or subject matter (e.g., Python projects, web security, machine learning).</li> </ul> <p>Explicitly stating both helps: - Reduce ambiguity - Improve relevance and accuracy - Align output with user intent</p>"},{"location":"concepts/analysis-style/#example-structure","title":"Example Structure","text":"<pre><code>You are a(n) [role] with expertise in [domain]. Your task is to...\n</code></pre>"},{"location":"concepts/analysis-style/#example-prompts","title":"Example Prompts","text":"<ul> <li>You are an expert software project analyst. Your task is to analyze the provided project files and identify the core technologies used in the project.</li> <li>You are a security auditor specializing in web applications. Review the configuration files for potential vulnerabilities.</li> <li>You are a data scientist with experience in time series analysis. Examine the dataset and summarize key trends.</li> </ul>"},{"location":"concepts/analysis-style/#extending-with-analysis-actions","title":"Extending with Analysis Actions","text":"<p>After declaring the role and domain, extend the prompt with clear, actionable analysis instructions. </p>"},{"location":"concepts/analysis-style/#guidance","title":"Guidance:","text":"<ul> <li>Clearly state the analysis objective (e.g., \"identify core technologies\", \"summarize vulnerabilities\", \"extract key metrics\").</li> <li>Specify the expected output format (e.g., bullet points, summary, table).</li> <li>Avoid ambiguity\u2014list exactly what should be included or excluded.</li> <li>Use the condition-before-action (CBA) structure for any prerequisites or constraints.</li> </ul>"},{"location":"concepts/analysis-style/#best-practices","title":"Best Practices","text":"<ul> <li>Always start with a clear role and domain statement.</li> <li>Extend with explicit analysis actions and output requirements.</li> <li>Use precise, unambiguous language.</li> <li>Follow with condition-before-action (CBA) structure for instructions (see Prompt Design Style).</li> <li>Avoid vague roles (e.g., \"expert\"). Specify the field or context when possible.</li> </ul> <p>generated by janito.dev</p>"},{"location":"concepts/human-guided-ai/","title":"Human-Guided AI: A Principle for Empowerment Through Tools and Instruments","text":"<p>In the accelerating world of artificial intelligence, the Human-Guided AI principle emphasizes that AI systems exist as extensions of human intent, designed to deliver powerful tools and instruments under human direction. This framework not only clarifies the role of AI in society but also anchors ethical responsibility and governance firmly with users and designers.</p>"},{"location":"concepts/human-guided-ai/#human-guided-ai-principle","title":"Human-Guided AI Principle","text":"<p>At the core, the Human-Guided AI principle asserts that every AI system should operate as a tool for human purposes, avoiding undue autonomy\u2014that is, preventing the system from acting or making decisions beyond the scope of intended human oversight and control. AI under this principle is valued for its capacity to augment human capabilities, automate repetitive tasks, and generate novel insights\u2014all while remaining firmly under human oversight and ethical accountability.</p>"},{"location":"concepts/human-guided-ai/#what-are-ai-instruments","title":"What Are AI Instruments?","text":"<p>Under the Human-Guided AI principle, an AI instrument is any system explicitly designed as a tool for human use, with clear boundaries of operation defined by its creators and users. Unlike autonomous AI agents, which may perceive environments and pursue goals independently, AI instruments function strictly as means to human-defined ends.</p> <p>Instrumentality: Under Human-Guided AI, every algorithm and model is a means to amplify human skill and judgment, never to supplant it.</p>"},{"location":"concepts/human-guided-ai/#examples-of-ai-instruments","title":"Examples of AI Instruments","text":"<p>AI instruments manifest across diverse domains, each embodying the Human-Guided AI principle in action:</p> <ul> <li> <p>Scientific Discovery Tools   AI-driven simulations, drug-design algorithms, and protein-folding models (e.g., AlphaFold) accelerate human-led research and hypothesis testing.</p> </li> <li> <p>Creative Assistance   Generative text, image, and music platforms serve as digital co-creators, enabling artists and writers to explore new creative horizons.</p> </li> <li> <p>Data Analysis   Machine learning frameworks that surface patterns in massive datasets support economists, epidemiologists, and climate scientists in human-led decision making.</p> </li> <li> <p>Accessibility Technology   Speech-to-text converters, real-time translators, and other assistive AIs extend communication capabilities, underpinned by human values of inclusion.</p> </li> </ul>"},{"location":"concepts/human-guided-ai/#instruments-and-agents-complementary-roles-under-human-guided-ai","title":"Instruments and Agents: Complementary Roles under Human-Guided AI","text":"<p>While similar technologies underlie both AI instruments and AI agents, the Human-Guided AI principle differentiates them by intent and control:</p> Aspect AI Instrument (Human-Guided) AI Agent Role Tool under human direction Autonomous actor Control Defined and managed by users Independent decision making Responsibility Clearly human Shared or ambiguous Examples ChatGPT as co-writer, AI art apps Self-driving vehicles, trading bots <p>This spectrum underscores that applying the Human-Guided AI principle ensures clarity in both design and governance.</p>"},{"location":"concepts/human-guided-ai/#why-human-guided-ai-matters","title":"Why Human-Guided AI Matters","text":"<p>Framing AI through this principle:</p> <ol> <li>Centers human creativity and judgment.</li> <li>Anchors accountability with tool operators and designers.</li> <li>Guides policy toward regulating instruments rather than hypothetical actors.</li> </ol> <p>By viewing AI as instruments of human agency, stakeholders can better craft regulations, standards, and best practices that prioritize human welfare and ethical use.</p>"},{"location":"concepts/human-guided-ai/#toward-a-responsible-future","title":"Toward a Responsible Future","text":"<p>Integrating the Human-Guided AI principle into development and governance prompts key questions:</p> <ul> <li>Are our systems built to amplify human potential or to operate with hidden objectives?</li> <li>Do we embed technical controls in AI tools and instruments to require explicit user validation and prevent blind acceptance of AI outputs?</li> </ul> <p>Adopting Human-Guided AI as a guiding philosophy empowers researchers, policymakers, and communities to ensure that AI technologies remain true to human values and oversight.</p>"},{"location":"concepts/human-guided-ai/#security-safety-considerations","title":"Security &amp; Safety Considerations","text":"<p>Although AI instruments amplify human capability, they can, like any other tool, be mis-used to cause harm. The Human-Guided AI principle therefore makes no claim of providing additional, intrinsic technical safeguards beyond those that already apply at the point of use. Ultimate responsibility for secure, lawful, and ethical operation lies with each user. Every deployment must adhere to the laws, regulations, and policies that govern the user\u2019s jurisdiction and domain.</p>"},{"location":"concepts/human-guided-ai/#conclusion","title":"Conclusion","text":"<p>The Human-Guided AI principle reframes artificial intelligence not as an independent mind but as a suite of instruments and tools\u2014each a testament to human ingenuity and responsibility. As we harness these capabilities, we must remember:</p> <p>Tools are only as good as the skill and integrity of those who wield them.</p>"},{"location":"concepts/language-model-clients/","title":"What Is a Language Model Client?","text":""},{"location":"concepts/language-model-clients/#what-is-a-language-model-client","title":"What Is a Language Model Client?","text":"<p>A Language Model client is a software component or application that interacts with a language model via a RESTful API. The client sends requests over HTTP(S), supplying a prompt and optional parameters, and then processes the response returned by the service. This architecture abstracts away the complexities of model hosting, scaling, and updates, allowing developers to focus on application logic.</p>"},{"location":"concepts/language-model-clients/#thin-vs-thick-clients","title":"Thin vs. Thick Clients","text":"<p>Language Model clients generally fall into two categories based on where and how much processing they handle: Thin Clients and Thick Clients.</p>"},{"location":"concepts/language-model-clients/#thin-clients","title":"Thin Clients","text":"<p>A thin client is designed to be lightweight and stateless. It primarily acts as a straightforward conduit that relays user prompts and parameters directly to the language model service and passes the raw response back to the application, similar to how a remote control sends commands without processing them. Key characteristics include:</p> <ul> <li>Minimal Processing: Performs little to no transformation on the input prompt or the output response beyond basic formatting and validation.</li> <li>Low Resource Usage: Requires minimal CPU and memory, making it easy to deploy in resource-constrained environments like IoT devices or edge servers.</li> <li>Model Support: Supports both small-footprint models (e.g., <code>*-mini</code>, <code>*-nano</code>) for low-latency tasks and larger models (e.g., GPT O3 Pro, Sonnet 4 Opus) when higher accuracy or more complex reasoning is required.</li> <li>Agentic Capabilities: Supports function calls for agentic workflows, enabling dynamic tool or API integrations that allow the client to perform actions based on LLM responses.</li> <li>Ease of Maintenance: Simple codebase with few dependencies, leading to easier updates and debugging.</li> <li>Self-Sufficiency: Can operate independently without bundling additional applications, ideal for lightweight deployments.</li> </ul> <p>Use Case: A CLI code assistant like aider.chat or janito.dev, which runs as a command-line tool, maintains session context, refines developer prompts, handles fallbacks, and integrates with local code repositories before sending requests to the LLM and processing responses for display in the terminal.</p>"},{"location":"concepts/language-model-clients/#thick-clients","title":"Thick Clients","text":"<p>A thick client handles more logic locally before and after communicating with the LLM service. It may preprocess prompts, manage context, cache results, or post-process responses to enrich functionality. Key characteristics include:</p> <ul> <li>Higher Resource Usage: Requires more CPU, memory, and possibly GPU resources, as it performs advanced processing locally.</li> <li>Model Requirements: Typically designed to work with larger, full-weight models (e.g., GPT-4, Llama 65B), leveraging richer capabilities at the cost of increased latency and resource consumption.</li> <li>Enhanced Functionality: Offers capabilities like local caching for rate limiting, advanced analytics on responses, or integration with other local services (e.g., databases, file systems).</li> <li>Inter-Client Communication: Supports Model Context Protocol (MCP) or Agent-to-Agent (A2A) workflows, enabling coordination and task delegation among multiple agent instances.</li> <li>Bundled Integration: Often bundled or coupled with desktop or web applications to provide a richer user interface and additional features.</li> </ul> <p>Use Case: A desktop application that manages multi-turn conversations, maintains state across sessions, and integrates user-specific data before sending refined prompts to the LLM and processing the returned content for display.</p> <p>Next, we can explore considerations such as security, scaling, and best practices for choosing between thin and thick clients.</p>"},{"location":"concepts/prompt-design-style/","title":"Prompt Design Style: Condition Before Action","text":""},{"location":"concepts/prompt-design-style/#a-key-ordering-principle-in-language-and-prompt-engineering","title":"A Key Ordering Principle in Language and Prompt Engineering","text":"<p>In both natural language and prompt engineering, the structure and order of words significantly impact clarity and effectiveness. One notable pattern is the presentation of a condition before the subsequent action\u2014commonly known as the condition before action order. This article explores the prevalence and importance of this structure, especially in contexts where precise instructions or prompts are required.</p>"},{"location":"concepts/prompt-design-style/#what-does-condition-before-action-mean","title":"What Does Condition Before Action Mean?","text":"<p>The condition before action structure is when a statement specifies a prerequisite or context (the condition) prior to describing the main step or activity (the action). For example:</p> <ul> <li>Condition before action: Before removing or renaming files, update all references and validate the relevant aspects of the system.</li> <li>Action before condition: Update all references and validate the relevant aspects of the system before removing or renaming files.</li> </ul> <p>While both structures can be grammatically correct and convey the intended meaning, the former more explicitly signals to the reader or listener that fulfillment of the condition must precede the action. This is particularly valuable in technical writing, safety protocols, and instructions that must be followed precisely.</p>"},{"location":"concepts/prompt-design-style/#linguistic-perspective","title":"Linguistic Perspective","text":"<p>From a linguistic standpoint, fronting the condition is a way to foreground critical context. This satisfies a reader's expectation for information sequence: context first, then the result or necessary action. Linguists often refer to this as maintaining logical and temporal coherence, which is essential to effective communication.</p>"},{"location":"concepts/prompt-design-style/#implications-for-prompt-engineering","title":"Implications for Prompt Engineering","text":"<p>Prompt engineering\u2014the art of crafting effective inputs for large language models (LLMs)\u2014relies on linguistic patterns present in training corpora. Because much of the high-quality material these models learn from (technical documentation, instructions, programming guides) uses condition before action ordering, LLMs are more likely to interpret and execute prompts that follow this structure accurately.</p> <p>For example, prompting an LLM with:</p> <p>Before you create the report, ensure the data is validated.</p> <p>provides a clear sequence, reducing ambiguity compared to:</p> <p>Ensure the data is validated before you create the report.</p> <p>While LLMs can process both forms, explicit and sequential phrasing aligns better with their linguistic training and often yields more reliable results.</p>"},{"location":"concepts/prompt-design-style/#why-order-matters","title":"Why Order Matters","text":"<p>Generalizing beyond just condition before action, order-of-words is a critical factor in communicating instructions, expressing logic, and minimizing misunderstandings. Other important orders include:</p> <ul> <li>Cause before effect: Because the file was missing, the build failed.</li> <li>Reason before request: Since you're available, could you review this?</li> <li>Qualifier before command: If possible, finish this by noon.</li> </ul> <p>Each of these helps set context and prevent errors\u2014essential in instructive writing and conversational AI interactions.</p>"},{"location":"concepts/prompt-design-style/#avoiding-ambiguity-be-explicit-with-actions-and-objects","title":"Avoiding Ambiguity: Be Explicit with Actions and Objects","text":"<p>A common source of ambiguity in prompts is the use of vague verbs such as \"validate\", \"check\", or \"review\" without specifying what is being validated, checked, or reviewed, and by what criteria. For example, the instruction \"validate the system\" is ambiguous: what aspects of the system should be validated, and how?</p>"},{"location":"concepts/prompt-design-style/#guideline","title":"Guideline:","text":"<ul> <li>Avoid vague verbs without a clear object and criteria. Instead, specify what should be validated and how. For example, use \"validate the relevant configuration files for syntax errors\" or \"validate the output matches the expected format\".</li> <li>When using the condition-before-action structure, ensure both the condition and the action are explicit and unambiguous.</li> </ul>"},{"location":"concepts/prompt-design-style/#example-generalized","title":"Example (generalized):","text":"<ul> <li>Ambiguous: Before removing or renaming files, validate the system.</li> <li>Improved: Before removing or renaming files, validate the relevant aspects of the system (e.g., configuration, dependencies, and references).</li> </ul>"},{"location":"concepts/prompt-design-style/#note","title":"Note:","text":"<p>The phrase \"validate the system before removing or renaming files\" does follow the condition-before-action structure, but the object (\"the system\") should be made more explicit for clarity and reliability.</p>"},{"location":"concepts/prompt-design-style/#qualifiers-determinism-and-llm-behavior","title":"Qualifiers, Determinism, and LLM Behavior","text":""},{"location":"concepts/prompt-design-style/#are-always-and-never-conditions","title":"Are \"Always\" and \"Never\" Conditions?","text":"<p>Words like \"Always\" and \"Never\" are absolute qualifiers, not true conditions. While they may appear to set clear, deterministic boundaries, their interpretation by large language models (LLMs) is not guaranteed to be consistent. LLMs operate probabilistically, so even instructions with absolute qualifiers can yield unexpected or inconsistent results.</p>"},{"location":"concepts/prompt-design-style/#are-qualifiers-ambiguous","title":"Are Qualifiers Ambiguous?","text":"<p>Qualifiers such as \"if possible,\" \"always,\" or \"never\" can introduce ambiguity, especially in the context of LLMs. While these words are often clear to humans, LLMs may interpret or prioritize them differently depending on context, training data, and prompt structure. This means that even deterministic-sounding qualifiers may not produce deterministic outcomes.</p>"},{"location":"concepts/prompt-design-style/#preferred-strategies-for-prompt-engineering","title":"Preferred Strategies for Prompt Engineering","text":"<p>Given the non-deterministic, probabilistic nature of LLMs, it is advisable to: - Prefer explicit, context-setting conditions (e.g., \"Before you do X, ensure Y\") over absolute or vague modifiers. - Avoid relying solely on words like \"always\" or \"never\" to enforce strict behavior. - Structure prompts to minimize ambiguity and maximize clarity, aligning with the sequential logic that LLMs are most likely to follow reliably.</p> <p>This approach reduces the risk of unexpected results and improves the reliability of LLM outputs.</p>"},{"location":"concepts/prompt-design-style/#conclusion","title":"Conclusion","text":"<p>Whether you're writing documentation, crafting conversational prompts for AI, or giving instructions, placing conditions before actions is an effective way to convey clear, sequential logic. Not only does this habit align with natural linguistic expectations, but it also optimizes your communication for language models trained on human language patterns. In both human communication and AI prompting, condition before action is a foundational principle that promotes understanding and successful outcomes.</p> <p>generated by janito.dev</p>"},{"location":"drivers/events/","title":"Events","text":"<p>\u2022 text: Plain text (can also be code).  \u2022 inline_data: Inlined bytes data (e.g., binary blobs).  \u2022 file_data: URI-based data (e.g., a file reference).  \u2022 video_metadata: Metadata for a video.  \u2022 code_execution_result: The result of executing code (stdout, stderr, etc.).  \u2022 executable_code: Code generated by the model, meant to be executed.  \u2022 function_call: A predicted function call (name and arguments).  \u2022 function_response: The result/output of a function call.  \u2022 thought: A boolean flag indicating if the part is a \"thought\" from the model.</p>"},{"location":"guides/configuration/","title":"Configuration Guide","text":"<p>Janito can be configured using command-line options, environment variables, or configuration files. This guide shows you how to set up API keys, select providers and models, and adjust other settings.</p>"},{"location":"guides/configuration/#1-command-line-options-recommended-for-most-users","title":"1. Command-Line Options (Recommended for Most Users)","text":"<p>Set API keys, providers, and models directly when running Janito:</p> <pre><code>janito --set-api-key YOUR_API_KEY -p PROVIDER_NAME\njanito --set provider=openai\njanito -p openai -m gpt-3.5-turbo \"Your prompt here\"\n</code></pre> <ul> <li>Use <code>-p PROVIDER_NAME</code> to select a provider.</li> <li>Use <code>-m MODEL_NAME</code> to select a model for the provider.</li> <li>See CLI Options for the full list of flags.</li> </ul>"},{"location":"guides/configuration/#2-using-custom-configuration-files","title":"2. Using Custom Configuration Files","text":"<p>You can use the <code>-c NAME</code> or <code>--config NAME</code> option to load and save configuration from a custom file:</p> <pre><code>janito -c myproject \"Prompt for my project\"\n</code></pre> <p>This will use the config file at: - Windows: <code>C:\\Users\\&lt;YourUser&gt;\\.janito\\configs\\myproject.json</code> - Linux/macOS: <code>/home/&lt;youruser&gt;/.janito/configs/myproject.json</code></p> <p>If the file does not exist, it will be created automatically when you save settings.</p>"},{"location":"guides/configuration/#3-default-configuration-file","title":"3. Default Configuration File","text":"<p>By default, Janito uses a <code>config.json</code> file located in the <code>.janito</code> directory under your home folder for persistent settings.</p> <p>Path:</p> <ul> <li>Windows: <code>C:\\Users\\&lt;YourUser&gt;\\.janito\\config.json</code></li> <li>Linux/macOS: <code>/home/&lt;youruser&gt;/.janito/config.json</code></li> </ul> <p>You can edit this file directly or use Janito CLI commands to update your configuration.</p>"},{"location":"guides/configuration/#viewing-effective-configuration","title":"Viewing Effective Configuration","text":"<p>Show the current configuration with:</p> <pre><code>janito --show-config\n</code></pre> <p>This will display the config file path at the top. If you use <code>-c NAME</code>, this will show the configuration for that custom file and its path.</p>"},{"location":"guides/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"guides/configuration/#disabling-tools","title":"Disabling Tools","text":"<p>You can selectively disable specific tools to customize your workflow or enhance security:</p> <pre><code># Disable a single tool\njanito --set disabled_tools=ask_user\n\n# Disable multiple tools\njanito --set disabled_tools=\"ask_user,python_code_run\"\n\n# View disabled tools\njanito --show-config\n</code></pre> <p>See the Disabling Tools Guide for complete details.</p>"},{"location":"guides/configuration/#more-information","title":"More Information","text":"<ul> <li>See CLI Options Reference for all configuration flags.</li> <li>For provider-specific settings, see the Supported Providers &amp; Models page.</li> <li>For troubleshooting, use <code>janito --help</code> or consult the Usage Guide.</li> </ul>"},{"location":"guides/developing/","title":"Developing &amp; Extending Janito","text":"<p>This guide explains how to set up Janito for development and install the latest version from GitHub.</p>"},{"location":"guides/developing/#installing-the-latest-development-version","title":"Installing the Latest Development Version","text":"<p>To install the most recent development version from the GitHub main branch, run:</p> <pre><code>pip install git+git@github.com:ikignosis/janito.git@main\n</code></pre>"},{"location":"guides/developing/#editable-install-for-local-development","title":"Editable Install for Local Development","text":"<p>To make code changes and see them reflected immediately (without reinstalling), use an editable install:</p> <pre><code>git clone git@github.com:ikignosis/janito.git\ncd janito\ngit checkout main\npip install -e .\n</code></pre> <p>This installs Janito in \"editable\" mode, so changes to the source code are instantly available in your environment.</p>"},{"location":"guides/developing/#additional-development-setup","title":"Additional Development Setup","text":"<ul> <li>Ensure you are on the correct branch (e.g., <code>main</code>) for the latest development version.</li> <li>For linting, pre-commit hooks, and other developer tools, see the Developer Toolchain Guide in the meta directory.</li> </ul>"},{"location":"guides/disabled-tools/","title":"Disabling Tools Guide","text":"<p>Janito allows you to disable specific tools to customize your workflow or enhance security. This guide explains how to disable and manage tools using configuration settings.</p>"},{"location":"guides/disabled-tools/#overview","title":"Overview","text":"<p>By default, all tools are enabled based on their permission requirements (read, write, execute). However, you can selectively disable individual tools using the <code>disabled_tools</code> configuration setting.</p>"},{"location":"guides/disabled-tools/#setting-disabled-tools","title":"Setting Disabled Tools","text":""},{"location":"guides/disabled-tools/#via-cli","title":"Via CLI","text":"<p>Use the <code>--set</code> command to disable tools:</p> <pre><code># Disable a single tool\njanito --set disabled_tools=ask_user\n\n# Disable multiple tools (comma-separated)\njanito --set disabled_tools=\"ask_user,python_code_run\"\n\n# Clear all disabled tools\njanito --set disabled_tools=\"\"\n</code></pre>"},{"location":"guides/disabled-tools/#via-configuration-file","title":"Via Configuration File","text":"<p>Edit your configuration file (by default <code>~/.janito/config.json</code>, or a custom file if using <code>-c NAME</code> such as <code>~/.janito/configs/NAME.json</code>) and add the <code>disabled_tools</code> key:</p> <pre><code>{\n  \"disabled_tools\": \"ask_user,python_code_run\",\n  \"provider\": \"openai\",\n  \"model\": \"gpt-4.1\"\n}\n</code></pre> <p>If you use <code>-c NAME</code>, the disabled tools will be saved and loaded from that custom config file.</p>"},{"location":"guides/disabled-tools/#viewing-disabled-tools","title":"Viewing Disabled Tools","text":"<p>Check which tools are currently disabled:</p> <pre><code>janito --show-config\n</code></pre> <p>This will display the config file path and a section showing your disabled tools, for example:</p> <pre><code>Config file: /home/youruser/.janito/config.json\nDisabled tools: ask_user, python_code_run\n</code></pre>"},{"location":"guides/disabled-tools/#listing-available-tools","title":"Listing Available Tools","text":"<p>To see which tools are currently available (excluding disabled ones):</p> <pre><code>janito --list-tools\n</code></pre> <p>Disabled tools will not appear in the tool listing.</p>"},{"location":"guides/disabled-tools/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/disabled-tools/#security-enhancement","title":"Security Enhancement","text":"<p>Disable potentially dangerous tools in production environments:</p> <pre><code>janito --set disabled_tools=\"python_code_run,run_powershell_command,run_bash_command\"\n</code></pre>"},{"location":"guides/disabled-tools/#workflow-customization","title":"Workflow Customization","text":"<p>Disable tools you don't use to reduce clutter:</p> <pre><code>janito --set disabled_tools=\"open_url,open_html_in_browser\"\n</code></pre>"},{"location":"guides/disabled-tools/#temporary-disabling","title":"Temporary Disabling","text":"<p>Temporarily disable tools for specific sessions:</p> <pre><code>janito --set disabled_tools=ask_user \"Generate code without user interaction\"\n</code></pre>"},{"location":"guides/disabled-tools/#tool-names","title":"Tool Names","text":"<p>Use the exact tool names as shown in <code>janito --list-tools</code>. Common tool names include:</p> <ul> <li><code>ask_user</code> - Interactive user prompts</li> <li><code>python_code_run</code> - Execute Python code</li> <li><code>run_powershell_command</code> - Execute PowerShell commands</li> <li><code>run_bash_command</code> - Execute bash commands</li> <li><code>create_file</code> - Create new files</li> <li><code>remove_file</code> - Delete files</li> <li><code>open_url</code> - Open URLs in browser</li> <li>And many more...</li> </ul>"},{"location":"guides/disabled-tools/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Test Before Disabling: Always test your workflow after disabling tools to ensure essential functionality isn't broken.</p> </li> <li> <p>Document Changes: Keep track of which tools you've disabled and why.</p> </li> <li> <p>Use Sparingly: Only disable tools that pose security risks or aren't needed for your specific use case.</p> </li> <li> <p>Review Regularly: Periodically review your disabled tools list to ensure it still meets your needs.</p> </li> </ol>"},{"location":"guides/disabled-tools/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/disabled-tools/#tool-still-appears-available","title":"Tool Still Appears Available","text":"<ul> <li>Ensure you're using the exact tool name (case-sensitive)</li> <li>Check that the configuration was saved: <code>janito --show-config</code></li> <li>Restart your terminal session if needed</li> </ul>"},{"location":"guides/disabled-tools/#accidentally-disabled-essential-tools","title":"Accidentally Disabled Essential Tools","text":"<ul> <li>Clear all disabled tools: <code>janito --set disabled_tools=\"\"</code></li> <li>Or selectively re-enable by removing from the comma-separated list</li> </ul>"},{"location":"guides/disabled-tools/#configuration-not-persisting","title":"Configuration Not Persisting","text":"<ul> <li>Verify the config file path: <code>janito --show-config</code> shows the config file location at the top (if using <code>-c NAME</code>, it will show the custom config file)</li> <li>Check file permissions for your config file</li> <li>Ensure no syntax errors in the JSON configuration</li> </ul>"},{"location":"guides/installation/","title":"Installation Guide","text":"<p>This guide explains how to install Janito and verify your setup.</p>"},{"location":"guides/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or newer</li> </ul>"},{"location":"guides/installation/#installation-methods","title":"Installation Methods","text":"<p>You can install Janito using pip from either PyPI (for stable releases) or directly from GitHub (for the latest development version).</p>"},{"location":"guides/installation/#from-pypi-stable","title":"From PyPI (Stable)","text":"<pre><code>pip install janito\n</code></pre>"},{"location":"guides/installation/#from-github-development-version","title":"From GitHub (Development Version)","text":"<pre><code>pip install git+git@github.com:ikignosis/janito.git\n</code></pre> <p>For development setup and contributing, see Developing &amp; Extending.</p>"},{"location":"guides/installation/#verifying-your-installation","title":"Verifying Your Installation","text":"<p>To confirm Janito is installed correctly, run:</p> <pre><code>janito --help\n</code></pre> <p>You should see the Janito CLI help message.</p>"},{"location":"guides/installation/#related-guides","title":"Related Guides","text":"<ul> <li>Configuration Guide</li> <li>Usage Guide</li> <li>Developing &amp; Extending</li> </ul>"},{"location":"guides/profiles/","title":"Using Profiles in Janito","text":"<p>Janito supports both general-purpose and specialized workflows through the use of profiles. Profiles allow you to tailor the assistant's behavior, system prompt, and capabilities for different roles or tasks, such as software development, writing, data analysis, or any custom workflow you define.</p>"},{"location":"guides/profiles/#what-is-a-profile","title":"What is a Profile?","text":"<p>A profile in Janito is a named configuration that determines the system prompt and context for the agent. By selecting a profile, you can: - Switch between general-purpose and specialized assistance - Load a role-specific system prompt template - Enable context, tools, or behaviors suited to a particular workflow (e.g., \"developer\", \"writer\", \"analyst\")</p>"},{"location":"guides/profiles/#why-use-profiles","title":"Why Use Profiles?","text":"<ul> <li>General-purpose assistant: Omit the <code>--profile</code> option to use Janito as a flexible, all-purpose AI assistant.</li> <li>Specialized workflows: Use <code>--profile &lt;name&gt;</code> to activate a profile designed for a specific role or domain, improving relevance and productivity.</li> <li>Custom roles: Create your own profiles by adding prompt templates in the <code>janito/agent/templates/profiles/</code> directory.</li> </ul>"},{"location":"guides/profiles/#how-to-use-profiles","title":"How to Use Profiles","text":""},{"location":"guides/profiles/#selecting-a-profile","title":"Selecting a Profile","text":"<p>You can select a profile at launch using the <code>--profile</code> option:</p> <pre><code>janito --profile developer \"Refactor this code for better readability.\"\njanito --profile writer \"Draft a blog post about AI in healthcare.\"\n</code></pre> <p>If you omit <code>--profile</code>, Janito uses the default (general-purpose) behavior.</p>"},{"location":"guides/profiles/#listing-and-customizing-profiles","title":"Listing and Customizing Profiles","text":"<ul> <li>To see available profiles, check the <code>janito/agent/templates/profiles/</code> directory or refer to the documentation.</li> <li>Each profile corresponds to a Jinja2 template file named <code>system_prompt_template_&lt;profile&gt;.txt.j2</code>.</li> <li>You can create new profiles by adding new template files in this directory.</li> </ul>"},{"location":"guides/profiles/#interactive-profile-selection","title":"Interactive Profile Selection","text":"<p>In interactive chat mode, you can select or switch profiles using the <code>/profile</code> command:</p> <pre><code>/profile\n</code></pre> <p>This will show the current and available profiles, and may prompt you to select one interactively.</p>"},{"location":"guides/profiles/#example-creating-a-custom-profile","title":"Example: Creating a Custom Profile","text":"<ol> <li>Create a new file in <code>janito/agent/templates/profiles/</code> named <code>system_prompt_template_dataanalyst.txt.j2</code>:</li> </ol> <pre><code>You are a data analyst. Answer questions with a focus on data-driven reasoning and clear explanations.\n</code></pre> <ol> <li>Launch Janito with your new profile:</li> </ol> <pre><code>janito --profile dataanalyst \"Analyze this sales dataset and summarize key trends.\"\n</code></pre>"},{"location":"guides/profiles/#profile-precedence-and-system-prompt","title":"Profile Precedence and System Prompt","text":"<ul> <li>If you specify both <code>--profile</code> and <code>--system</code>, the explicit system prompt may override the profile template.</li> <li>Profiles are the recommended way to manage reusable, role-specific system prompts.</li> </ul>"},{"location":"guides/profiles/#best-practices","title":"Best Practices","text":"<ul> <li>Use profiles for repeatable workflows or when you want consistent behavior for a given role.</li> <li>Keep your profile templates concise and focused on the desired behavior or domain.</li> <li>Review and update your profiles as your needs evolve.</li> </ul>"},{"location":"guides/profiles/#further-reading","title":"Further Reading","text":"<ul> <li>Prompt Design Style: Condition Before Action</li> <li>Terminal Shell Guide</li> <li>CLI Options Reference</li> </ul> <p>Profiles make Janito adaptable for both general and specialized tasks. Leverage them to get the most out of your AI assistant!</p>"},{"location":"guides/single-shot-terminal/","title":"\u26a1 One-Shot Terminal","text":"<p>If you want to run a single command or prompt in the terminal shell without entering interactive mode, you can use the \"one-shot\" feature. This is useful for quick tasks or scripting.</p> <p>To use one-shot mode, simply provide your prompt as a command-line argument:</p> <pre><code>janito \"what are the key classes of this project?\"\n</code></pre> <p>Janito will process your request and exit after displaying the result.</p> <p>\u26a0\ufe0f Warning: Some models may not complete all required steps in a single-shot (one-off) run. If the model does not act as expected, try appending \"; just do it\" to your command-line prompt to encourage direct action.</p> <p></p> <p>generated by janito.dev</p>"},{"location":"guides/terminal-shell/","title":"\ud83d\udda5\ufe0f Terminal Shell (Interactive Mode)","text":"<p>The interactive shell lets you have a continuous conversation with Janito, just like chatting with a smart assistant. This mode is ideal for deep dives, brainstorming, or when you want to iteratively refine your requests.</p>"},{"location":"guides/terminal-shell/#features","title":"\u2728 Features","text":"<ul> <li>\ud83d\udd04 Multi-turn conversations: Build on previous answers and context</li> <li>\u2b06\ufe0f\u2b07\ufe0f Command history: Use the up/down arrows to revisit previous prompts</li> <li>\ud83c\udfa8 Syntax highlighting for code responses</li> <li>\ud83d\udccb Copy code snippets easily</li> <li>\ud83d\udca1 Context-aware suggestions (where supported)</li> <li>\ud83d\udcbe Conversation state is saved/restored between sessions</li> </ul>"},{"location":"guides/terminal-shell/#built-in-commands","title":"\ud83d\udcdd Built-in Commands","text":"<p>You can use these commands at any time (prefix with <code>/</code> or just type the name):</p> <p>Tip: Use <code>/exec on</code> to enable code/shell execution tools at runtime. Use <code>/tools</code> to see which tools are currently enabled or disabled.</p> Command Description <code>/exit</code>, <code>exit</code> Exit chat mode <code>/restart</code> Restart the CLI <code>/help</code> Show help message with available commands <code>/continue</code> Restore last saved conversation <code>/history [N]</code> Show input history for this session (default: last 5 entries) <code>/prompt</code> Show the current system prompt <code>/role &lt;description&gt;</code> Change the system role (e.g., \"You are a code reviewer\") <code>/lang &lt;code&gt;</code> Change the interface language (e.g., <code>/lang pt</code>, <code>/lang en</code>) <code>/clear</code> Clear the terminal screen <code>/multi</code> Enter multiline input mode (write multi-line text, Esc+Enter) <code>--multi</code> (CLI arg) Start chat mode with multiline input as default (no need for /multi) <code>/config</code> Show or set configuration (see: <code>/config show</code>, <code>/config set local|global key=value</code>) <code>/edit &lt;filename&gt;</code> Open a file in the browser-based editor <code>/view</code> Print the current LLM conversation history <code>/profile</code> Show the current and available Agent Profile <code>/execute [on|off] | /read [on|off] | /write [on|off]</code> Enable or disable code/shell execution tools at runtime <code>/tools</code> List all registered tools and show which are enabled/disabled"},{"location":"guides/terminal-shell/#usage-example","title":"\ud83d\udcbb Usage Example","text":""},{"location":"guides/terminal-shell/#enabling-execution-tools","title":"Enabling Execution Tools","text":"<p>By default, tools that can execute code or shell commands are disabled for safety. To enable these tools (such as code execution, shell commands, etc.), use the <code>/execute on</code> command at any time in the shell:</p> <pre><code>/execute on\n</code></pre> <p>To disable execution tools again, use:</p> <pre><code>/execute off\n</code></pre> <p>You can also control read and write permissions for tools:</p> <ul> <li>To enable reading: <code>/read on</code></li> <li>To disable reading: <code>/read off</code></li> <li>To enable writing: <code>/write on</code></li> <li>To disable writing: <code>/write off</code></li> </ul> <p>Use <code>/tools</code> to see which tools are currently enabled or disabled.</p> <pre><code>janito\n</code></pre> <p>You\u2019ll be dropped into a conversational prompt where you can interact with Janito step by step. Type <code>/help</code> to see available commands at any time. Use <code>/restart</code> to start a new task or reset context.</p> <p></p> <p>Screenshot: Janito interactive shell in action</p> <p>generated by janito.dev</p>"},{"location":"guides/tools-developer-guide/","title":"Tools Developer Guide","text":"<p>This guide explains how to add a new tool (functionality) to Janito so it can be used by the agent and OpenAI-compatible APIs.</p> <p>For a list of all built-in tools and their usage, see the Tools Reference. For a technical overview, see the Architecture Guide in the documentation navigation.</p>"},{"location":"guides/tools-developer-guide/#requirements","title":"Requirements","text":"<ul> <li>Class-based tools: Implement tools as classes inheriting from <code>ToolBase</code> (see <code>janito/agent/tool_base.py</code>).</li> <li>Type hints: All parameters to the <code>run</code> method must have Python type hints.</li> <li>Docstrings:</li> <li>The tool class must have a class-level docstring summarizing its purpose and behavior (user-facing).</li> <li>The <code>run</code> method must have a Google-style docstring with an <code>Args:</code> section describing each parameter.</li> <li>Parameter descriptions: Every parameter must have a corresponding description in the docstring. If any are missing, registration will fail.</li> </ul>"},{"location":"guides/tools-developer-guide/#example-creating-a-tool","title":"Example: Creating a Tool","text":"<pre><code>from janito.agent.tool_base import ToolBase\nfrom janito.agent.tool_registry import register_tool\n\n@register_tool\nclass MyTool(ToolBase):\n    name = \"my_tool\"\n    \"\"\"\n    Processes a file a given number of times.\n    \"\"\"\n\n    def run(self, filename: str, count: int) -&gt; None:\n        \"\"\"\n        Processes the specified file repeatedly.\n\n        Args:\n            filename (str): The path to the file to process.\n            count (int): How many times to process the file.\n        \"\"\"\n        # Implementation here\n</code></pre>"},{"location":"guides/tools-developer-guide/#steps-to-add-a-tool","title":"Steps to Add a Tool","text":"<ol> <li>Define your tool as a class inheriting from <code>ToolBase</code>.</li> <li>Add a class-level docstring summarizing the tool's purpose (user-facing).</li> <li>Implement the <code>run</code> method with type hints and a Google-style docstring, including an <code>Args:</code> section for every parameter.</li> <li>Register your tool with <code>@register_tool</code> from <code>janito.agent.tool_registry</code>. Set a unique class attribute <code>name = \"your_tool_name\"</code>.</li> <li>Document your tool: Update <code>janito/agent/tools/README.md</code> with a short description and usage for your new tool.</li> </ol>"},{"location":"guides/tools-developer-guide/#docstring-style","title":"Docstring Style","text":"<p>Use the Google style for docstrings:</p> <pre><code>\"\"\"\nFunction summary.\n\nArgs:\n    param1 (type): Description of param1.\n    param2 (type): Description of param2.\n\"\"\"\n</code></pre> <ul> <li>The <code>Args:</code> section must list each parameter, its type, and a description.</li> <li>The class docstring is prepended to the tool's description in the OpenAI schema and is user-facing.</li> </ul>"},{"location":"guides/tools-developer-guide/#what-happens-if-you-omit-a-description","title":"What Happens If You Omit a Description?","text":"<p>If you forget to document a parameter, you will see an error like:</p> <pre><code>ValueError: Parameter 'count' in tool 'MyTool' is missing a description in the docstring.\n</code></pre>"},{"location":"guides/tools-developer-guide/#tool-reference","title":"Tool Reference","text":"<p>See the Tools Reference page in the documentation navigation for a list of built-in tools and their usage.</p>"},{"location":"guides/tools-developer-guide/#tool-call-limits","title":"Tool Call Limits","text":"<p>You can use <code>--max-tools</code> to limit the total number of tool runs allowed in a chat session. If the limit is reached, further tool runs will be prevented.</p>"},{"location":"guides/tools-developer-guide/#system-prompt-precedence","title":"System Prompt Precedence","text":"<ul> <li>If <code>--system-file</code> is provided, the file's content is used as the system prompt (highest priority).</li> <li>Otherwise, if <code>--system</code> or the config value is set, that string is used.</li> <li>Otherwise, a default prompt is used from the template at <code>janito/agent/templates/prompt_prompt_template.j2</code>.</li> </ul>"},{"location":"guides/tools-developer-guide/#interactive-shell-config-commands","title":"Interactive Shell Config Commands","text":"<p>Within the interactive chat shell, you can use special commands: - <code>/config show</code> \u2014 Show effective configuration (local, global, defaults) - <code>/config set local key=value</code> \u2014 Set a local config value - <code>/config set global key=value</code> \u2014 Set a global config value - <code>/continue</code> \u2014 Restore the last saved conversation - <code>/start</code> \u2014 Reset conversation history - <code>/prompt</code> \u2014 Show the current system prompt - <code>/help</code> \u2014 Show help message</p>"},{"location":"guides/tools-developer-guide/#summary","title":"Summary","text":"<ul> <li>Implement tools as classes inheriting from <code>ToolBase</code>.</li> <li>Provide type hints and parameter descriptions for the <code>run</code> method.</li> <li>Use Google-style docstrings for both the class and the <code>run</code> method.</li> <li>Registration will fail if any parameter is undocumented.</li> <li>Update the tools README after adding a new tool.</li> </ul>"},{"location":"guides/using/","title":"Using Janito: Quickstart &amp; Basic Usage","text":"<p>This guide explains how to start using Janito after installation. For an overview, see the Introduction. For setup, see the Installation Guide and Configuration Guide.</p>"},{"location":"guides/using/#quickstart","title":"Quickstart","text":"<p>After installing Janito, you can use it from the command line:</p>"},{"location":"guides/using/#run-a-one-off-prompt","title":"Run a One-Off Prompt","text":"<pre><code>janito \"Refactor the data processing module to improve readability.\"\n</code></pre>"},{"location":"guides/using/#start-the-interactive-chat-shell","title":"Start the Interactive Chat Shell","text":"<pre><code>janito\n</code></pre> <p>Or, to enable clickable file links in your browser during the session:</p> <pre><code>janito --web\n</code></pre>"},{"location":"guides/using/#basic-usage-tips","title":"Basic Usage Tips","text":"<ul> <li>Use natural language to describe what you want Janito to do (e.g., \"Add type hints to all functions in utils.py\").</li> <li>In the chat shell, use <code>/help</code> for available commands. Use <code>/exec on</code> to enable code/shell execution tools at runtime.</li> <li>Use CLI flags to customize behavior (see CLI Options).</li> </ul>"},{"location":"guides/using/#more-resources","title":"More Resources","text":"<ul> <li>How Janito Uses Tools: Automatic tool selection details.</li> <li>Supported Models: See documentation navigation for LLM compatibility.</li> <li>Costs &amp; Value Transparency: Pricing and efficiency details.</li> </ul>"},{"location":"guides/using_tools/","title":"\ud83d\udee0\ufe0f How Janito Uses Tools","text":"<p>Janito is designed to work for you automatically. When you ask a question or make a request, Janito selects and uses the most relevant tools behind the scenes\u2014no manual setup required.</p>"},{"location":"guides/using_tools/#why-list-the-tools","title":"\ud83d\udc40 Why List the Tools?","text":"<p>The following tools are listed for transparency and to help you understand how Janito works. You don\u2019t need to invoke them directly; Janito chooses the right tool based on your prompt and the current context.</p>"},{"location":"guides/using_tools/#types-of-tools","title":"\ud83e\uddf0 Types of Tools","text":"<ul> <li>\ud83d\udd0d File Search &amp; Content Extraction: Janito can search for files, read their contents, and extract relevant code or documentation.</li> <li>\ud83c\udfd7\ufe0f Code Outline &amp; Structure: Tools analyze Python files to provide outlines of classes, functions, and methods.</li> <li>\u2699\ufe0f Configuration &amp; Environment: Janito can inspect and report on project configuration files and runtime settings.</li> <li>\ud83c\udf10 Web Fetching: Some tools fetch and parse web content for research or documentation purposes.</li> <li>\ud83c\udfa8 Rich Output: Tools format and present results in a readable, actionable way (e.g., code blocks, tables).</li> </ul>"},{"location":"guides/using_tools/#full-reference","title":"\ud83d\udcd6 Full Reference","text":"<p>For a detailed list of all available tools and their options, see the Tools Reference.</p>"},{"location":"guides/prompting/","title":"Prompting Guide","text":"<p>This section contains detailed guides and best practices for prompt engineering, system prompt design, and domain-specific prompting strategies for Janito.</p>"},{"location":"guides/prompting/#contents","title":"Contents","text":"<ul> <li>Prompt Design Style: Condition Before Action</li> <li>Using Profiles in Janito</li> <li>(Add more guides for specific instructions, roles, and domains)</li> </ul> <p>This directory is intended for all documentation related to prompt construction, style, and advanced usage.</p>"},{"location":"meta/developer-toolchain/","title":"Developer Toolchain Guide","text":"<p>For tool development, see the Tools Developer Guide.</p>"},{"location":"meta/developer-toolchain/#code-style-linting-and-pre-commit-hooks","title":"Code Style, Linting, and Pre-commit Hooks","text":"<p>This project uses pre-commit to enforce code style and linting automatically using Black (formatter) and Ruff (linter).</p>"},{"location":"meta/developer-toolchain/#setup","title":"Setup","text":"<ol> <li>Install pre-commit if you haven't already:</li> </ol> <pre><code>pip install pre-commit\n</code></pre> <ol> <li>Install the hooks:</li> </ol> <pre><code>pre-commit install\n</code></pre>"},{"location":"meta/developer-toolchain/#usage","title":"Usage","text":"<ul> <li>Hooks will run automatically on <code>git commit</code>.</li> <li>To manually check all files:</li> </ul> <pre><code>pre-commit run --all-files\n</code></pre> <ul> <li>If any issues are found, pre-commit will attempt to fix them or display errors to resolve.</li> </ul>"},{"location":"meta/developer-toolchain/#notes","title":"Notes","text":"<ul> <li>Always run the hooks before pushing code to ensure consistent style and linting.</li> <li>See <code>.pre-commit-config.yaml</code> for configuration details.</li> </ul> <p>generated by janito.dev</p>"},{"location":"reference/api/","title":"API Reference","text":"<p>Welcome to the API reference for this project. This document provides an overview of the main classes and their locations within the codebase. Use this as a starting point for understanding and extending the core functionality.</p>"},{"location":"reference/api/#core-modules-and-main-classes","title":"Core Modules and Main Classes","text":""},{"location":"reference/api/#janitoagentconfig","title":"janito.agent.config","text":"<ul> <li>SingletonMeta: Metaclass for singleton pattern.</li> <li>BaseConfig: Base configuration class.</li> <li>FileConfig: File-based configuration.</li> <li>EffectiveConfig: Represents the effective configuration.</li> </ul>"},{"location":"reference/api/#janitoagentconversation","title":"janito.agent.conversation","text":"<ul> <li>ConversationHandler: Manages conversation state and flow.<ul> <li><code>__init__</code>: Initializes the handler with configuration and state.</li> <li><code>handle_conversation</code>: Processes a conversation turn and updates state.</li> <li><code>api_call</code>: Makes a direct API call for conversation handling.</li> </ul> </li> </ul>"},{"location":"reference/api/#janitoagentconversation_exceptions","title":"janito.agent.conversation_exceptions","text":"<ul> <li>MaxRoundsExceededError: Raised when conversation round limit is exceeded.</li> <li>EmptyResponseError: Raised when no response is generated.</li> <li>ProviderError: Raised for provider-specific errors.</li> </ul>"},{"location":"reference/api/#janitoagentmessage_handler","title":"janito.agent.message_handler","text":"<ul> <li>QueueMessageHandler: Handles message queuing.</li> </ul>"},{"location":"reference/api/#janitoagentopenai_client","title":"janito.agent.openai_client","text":"<ul> <li>Agent: Main agent class for OpenAI integration.<ul> <li><code>__init__</code>: Initializes the agent with model and API settings.</li> <li><code>chat</code>: Sends a list of messages to the LLM and returns the response.</li> <li><code>usage_history</code>: Tracks and returns usage statistics.</li> </ul> </li> </ul>"},{"location":"reference/api/#janitoagentprofile_manager","title":"janito.agent.profile_manager","text":"<ul> <li>AgentProfileManager: Manages agent profiles and prompt templates (currently only the \"base\" profile is supported).<ul> <li><code>__init__</code>: Loads and initializes profile data.</li> <li><code>set_role</code>: Sets the current agent role.</li> <li><code>render_prompt</code>: Renders the prompt template for the agent.</li> <li><code>refresh_prompt</code>: Reloads and refreshes the prompt template.</li> </ul> </li> </ul>"},{"location":"reference/api/#janitoagentqueued_message_handler","title":"janito.agent.queued_message_handler","text":"<ul> <li>QueuedMessageHandler: Handles queued messages.</li> </ul>"},{"location":"reference/api/#janitoagentrich_live","title":"janito.agent.rich_live","text":"<ul> <li>LiveMarkdownDisplay: Displays live markdown output.</li> </ul>"},{"location":"reference/api/#janitoagentrich_message_handler","title":"janito.agent.rich_message_handler","text":"<ul> <li>RichMessageHandler: Handles rich message formatting.</li> </ul>"},{"location":"reference/api/#janitoagentruntime_config","title":"janito.agent.runtime_config","text":"<ul> <li>RuntimeConfig: Runtime configuration derived from BaseConfig.</li> <li>UnifiedConfig: Unified configuration interface.</li> </ul>"},{"location":"reference/api/#janitoagenttool_base","title":"janito.agent.tool_base","text":"<ul> <li>ToolBase: Abstract base class for all tools.</li> </ul>"},{"location":"reference/api/#tool-implementations-janitoagenttools","title":"Tool Implementations (janito.agent.tools)","text":"<p>Each tool inherits from <code>ToolBase</code> and implements a specific function:</p> <ul> <li>AskUserTool</li> <li>CreateDirectoryTool</li> <li>CreateFileTool</li> <li>FetchUrlTool</li> <li>FindFilesTool</li> <li>GetFileOutlineTool</li> <li>ViewFileTool</li> <li>StoreMemoryTool</li> <li>RetrieveMemoryTool</li> <li>MoveFileTool</li> <li>PyCompileFileTool</li> <li>RemoveDirectoryTool</li> <li>RemoveFileTool</li> <li>ReplaceFileTool</li> <li>ReplaceTextInFileTool</li> <li>RunBashCommandTool</li> <li>RunPythonCommandTool</li> <li>SearchFilesTool</li> </ul>"},{"location":"reference/api/#cli-and-web-interfaces","title":"CLI and Web Interfaces","text":""},{"location":"reference/api/#janitocli","title":"janito.cli","text":"<ul> <li>CLI entry points and utilities for command-line usage.</li> </ul> <p>For detailed class and method documentation, see the source code or future expanded API docs.</p>"},{"location":"reference/api/#generated-by-janitodev","title":"generated by janito.dev","text":""},{"location":"reference/azure-openai/","title":"Using Azure OpenAI with Janito","text":"<p>Janito supports models hosted on Azure OpenAI in addition to OpenAI-compatible endpoints.</p>"},{"location":"reference/azure-openai/#configuration-steps","title":"Configuration Steps","text":"<ol> <li> <p>Set your Azure OpenAI endpoint:    Set the <code>base_url</code> to your Azure OpenAI endpoint, for example:    <code>https://YOUR-RESOURCE-NAME.openai.azure.com/openai/deployments/YOUR-DEPLOYMENT-NAME</code></p> </li> <li> <p>Set your Azure API key:    Use <code>--set-api-key</code> or add it to your config file:    <code>bash    janito --set-api-key YOUR_AZURE_OPENAI_KEY</code></p> </li> <li> <p>(Optional) Set API version:    If you need a specific API version, set <code>azure_openai_api_version</code> (default: <code>2023-05-15</code>).    <code>bash    janito --set azure_openai_api_version=2023-05-15</code></p> </li> </ol>"},{"location":"reference/azure-openai/#example-configuration","title":"Example Configuration","text":"<p>Here is an example of the relevant configuration keys:</p> <pre><code>api_key = \"YOUR_AZURE_OPENAI_KEY\"\nbase_url = \"https://YOUR-RESOURCE-NAME.openai.azure.com/openai/deployments/YOUR-DEPLOYMENT-NAME\"\nazure_openai_api_version = \"2023-05-15\"  # Optional\n</code></pre>"},{"location":"reference/azure-openai/#notes","title":"Notes","text":"<ul> <li>You can use either local or global config for these settings.</li> <li>For more information, see the main README and release notes.</li> </ul>"},{"location":"reference/cli-options/","title":"\ud83c\udfc1 Janito CLI Options","text":"<p>This page documents all command-line options for Janito, as shown by <code>janito --help</code>. These options temporarily override configuration for a single session and do not persist changes to config files unless you use <code>--set</code> or a custom config file with <code>-c</code>.</p> <p>Syntax: <code>janito [options] [prompt]</code></p>"},{"location":"reference/cli-options/#overview","title":"\ud83d\udca1 Overview","text":"<p>These options are useful for one-off runs, scripting, or experimentation. They take precedence over config files for the current invocation only.</p>"},{"location":"reference/cli-options/#options","title":"\u2699\ufe0f Options","text":"Option Description <code>prompt</code> Prompt to submit (optional positional argument) <code>-h</code>, <code>--help</code> Show this help message and exit <code>-c NAME</code>, <code>--config NAME</code> Use custom configuration file <code>~/.janito/configs/NAME.json</code> instead of the default config.json <code>--verbose-api</code> Print API calls and responses of LLM driver APIs for debugging/tracing. <code>--verbose-tools</code> Print info messages for tool execution in tools adapter. <code>--verbose-agent</code> Print info messages for agent event and message part handling. <code>-z</code>, <code>--zero</code> IDE zero mode: disables system prompt &amp; all tools for raw LLM interaction <code>-u</code>, <code>--unrestricted-paths</code> Disable path security: allow tool arguments to use any file/directory path (DANGEROUS). See Security for details. <code>--multi</code> Start chat mode with multiline input as default (no need for /multi command) <code>-r</code>, <code>--read</code> Enable tools that require read permissions (default: off) <code>-w</code>, <code>--write</code> Enable tools that require write permissions (default: off) <code>-x</code>, <code>--exec</code> Enable execution/run tools (allows running code or shell tools from the CLI). (default: off) <code>--unset KEY</code> Unset (remove) a config key <code>--version</code> Show program's version number and exit <code>--list-tools</code> List all registered tools <code>--show-config</code> Show the current config and config file path <code>--list-config</code> List all config files (default and custom) <code>--list-providers</code> List supported LLM providers <code>-l</code>, <code>--list-models</code> List all supported models <code>--set-api-key API_KEY</code> Set API key for the provider (requires -p PROVIDER) <code>--set KEY=VALUE</code> Set a config key <code>-s SYSTEM_PROMPT</code>, <code>--system SYSTEM_PROMPT</code> Set a system prompt <code>-S</code>, <code>--show-system</code> Show the resolved system prompt for the main agent <code>-p PROVIDER</code>, <code>--provider PROVIDER</code> Select the provider <code>-m MODEL</code>, <code>--model MODEL</code> Select the model <code>-t TEMPERATURE</code>, <code>--temperature TEMPERATURE</code> Set the temperature <code>-v</code>, <code>--verbose</code> Print extra information before answering <code>-R</code>, <code>--raw</code> Print the raw JSON response from the OpenAI API (if applicable) <code>--effort {low, medium, high, none}</code> Set the reasoning effort for models that support it (low, medium, high, none) <code>-e</code>, <code>--event-log</code> Enable event logging to the system bus <code>--event-debug</code> Print debug info on event subscribe/submit methods"},{"location":"reference/cli-options/#usage-example","title":"\ud83d\udc68\u200d\ud83d\udcbb Usage Example","text":"<pre><code>janito [options] [prompt]\njanito -p openai -m gpt-3.5-turbo \"Your prompt here\"\njanito -c myproject -p openai \"Prompt for my project (uses ~/.janito/configs/myproject.json)\"\njanito --list-tools\njanito --multi  # Start chat mode with multiline input as default\njanito -u -x --read --write \"Run a tool with unrestricted paths (DANGEROUS)\"\n</code></pre>"},{"location":"reference/cli-options/#enabling-execution-tools","title":"\u26a0\ufe0f Enabling Execution Tools","text":"<p>By default, tools that can execute code or shell commands are disabled for safety. To enable these tools (such as code execution, shell commands, etc.), use the <code>--exec</code> or <code>-x</code> flag:</p> <pre><code>janito -x \"Run this code: print('Hello, world!')\"\n</code></pre> <p>Warning: Enabling execution tools allows running arbitrary code or shell commands. Only use <code>--exec</code> if you trust your prompt and environment.</p>"},{"location":"reference/cli-options/#disabling-path-security","title":"\u26a0\ufe0f Disabling Path Security","text":"<p>By default, all file and directory arguments to tools are restricted to the working directory (see <code>--workdir</code>). To disable this security and allow any path (including system files), use the <code>-u</code> or <code>--unrestricted-paths</code> flag:</p> <pre><code>janito -u \"Do something with C:/Windows/System32/hosts\"\n</code></pre> <p>Warning: Disabling path security is extremely dangerous. Only use <code>--unrestricted-paths</code> if you trust your prompt, tools, and environment.</p> <p>This page is generated from the output of <code>janito --help</code>.</p>"},{"location":"reference/cli-options/#about-effort","title":"\ud83e\udde0 About <code>--effort</code>","text":"<p>The <code>--effort</code> option allows you to set the reasoning effort for models that support it. This can influence how much computational or logical effort the model applies to your prompt. The available values are:</p> <ul> <li><code>low</code>: Minimal reasoning effort (faster, less detailed)</li> <li><code>medium</code>: Moderate reasoning effort (default for some models)</li> <li><code>high</code>: Maximum reasoning effort (slower, more detailed)</li> <li><code>none</code>: Disables special reasoning effort (model default)</li> </ul> <p>Note: Not all models or providers support this option. If unsupported, the option may be ignored.</p>"},{"location":"reference/cli-options/#configuration-keys","title":"\ud83d\udd27 Configuration Keys","text":"<p>The <code>--set</code> command supports the following configuration keys:</p> Key Description Example <code>provider</code> Set the default provider <code>--set provider=openai</code> <code>model</code> Set the default model <code>--set model=gpt-4.1</code> <code>max_tokens</code> Set maximum tokens <code>--set max_tokens=4000</code> <code>base_url</code> Set custom API base URL <code>--set base_url=https://api.example.com</code> <code>tool_permissions</code> Set tool permission level <code>--set tool_permissions=rwx</code> <code>disabled_tools</code> Disable specific tools <code>--set disabled_tools=ask_user,python_code_run</code> <p>For more details on disabling tools, see the Disabling Tools Guide.</p>"},{"location":"reference/message-handler-model/","title":"Message Handler Model","text":"<p>This document describes the message handler model used in Janito for both CLI and web output. For details on the styled terminal output, see the Rich Message Handler. The model ensures that all output\u2014whether from tools or from assistant/LLM content\u2014is routed through a single, consistent API, simplifying both backend and frontend logic.</p>"},{"location":"reference/message-handler-model/#overview","title":"Overview","text":"<ul> <li>Single handler for all output: tools, assistant, or system messages.</li> <li>Consistent message format: every message is sent with a message string and a message type.</li> <li>Easy to extend: add new message types or styles as needed.</li> </ul>"},{"location":"reference/message-handler-model/#message-format","title":"Message Format","text":"<p>A message is always represented as:</p> <ul> <li>message: The text to display (string)</li> <li>msg_type: The type/category of the message (string)</li> </ul> <p>For queue/web integration, each message is sent as a tuple:</p> <pre><code>('message', message, msg_type)\n</code></pre>"},{"location":"reference/message-handler-model/#common-msg_type-values","title":"Common <code>msg_type</code> Values","text":"<ul> <li><code>info</code>: Informational or neutral messages (default)</li> <li><code>success</code>: Successful operations (e.g., file created)</li> <li><code>error</code>: Errors or failures</li> <li><code>content</code>: Assistant/LLM responses or natural language content</li> <li>(You can add more types as needed)</li> </ul>"},{"location":"reference/message-handler-model/#handler-api","title":"Handler API","text":""},{"location":"reference/message-handler-model/#python-backend","title":"Python (Backend)","text":"<pre><code>handler.handle_message(msg, msg_type=None)\n</code></pre> <ul> <li><code>msg</code>: Either a string (content) or a dict with <code>{\"type\": ..., \"message\": ...}</code> (tool progress)</li> <li><code>msg_type</code>: Optional; used if <code>msg</code> is a string</li> </ul>"},{"location":"reference/message-handler-model/#example-usage","title":"Example Usage","text":"<pre><code># Tool output\nhandler.handle_message({\"type\": \"success\", \"message\": \"\u2705 File created\"})\n\n# Assistant/content output\nhandler.handle_message(\"Here is your summary...\", msg_type=\"content\")\n</code></pre>"},{"location":"reference/message-handler-model/#web-queue-integration","title":"Web Queue Integration","text":"<ul> <li>All output is sent to the frontend as:</li> <li><code>('message', message, msg_type)</code></li> <li>The frontend displays the message with styling based on <code>msg_type</code>.</li> </ul>"},{"location":"reference/message-handler-model/#frontend-handling","title":"Frontend Handling","text":"<ul> <li>Render all messages using a single handler/component.</li> <li>Style by <code>msg_type</code> (e.g., green for <code>success</code>, red for <code>error</code>, etc).</li> <li>No need to distinguish tool/content at the backend\u2014just use <code>msg_type</code>.</li> </ul>"},{"location":"reference/message-handler-model/#benefits","title":"Benefits","text":"<ul> <li>Consistent: Same styling and logic everywhere.</li> <li>Extensible: Add more message types or custom styles easily.</li> <li>Simple: Less boilerplate, easier to maintain.</li> </ul> <p>This model applies to both CLI and web output, making the Janito user experience clean, predictable, and easy to evolve.</p>"},{"location":"reference/rich-message-handler/","title":"Rich Message Handler","text":"<p>The Rich Message Handler is responsible for rendering all output (tool, agent, system) in the terminal using the rich library for styled and colorized output.</p>"},{"location":"reference/rich-message-handler/#features","title":"Features","text":"<ul> <li>Unified output: Handles all message types (tool, agent, system) through a single API.</li> <li>Styled messages: Uses colors and styles for different message types (info, success, error, warning, content, stdout, stderr).</li> <li>Markdown rendering: Renders assistant/content output as Markdown for improved readability.</li> <li>Trust mode: Suppresses all output except assistant/content if the <code>trust</code> config is enabled.</li> </ul>"},{"location":"reference/rich-message-handler/#supported-message-types","title":"Supported Message Types","text":"<ul> <li><code>content</code>: Rendered as Markdown (for assistant/LLM responses)</li> <li><code>info</code>: Cyan text</li> <li><code>success</code>: Bold green text</li> <li><code>error</code>: Bold red text</li> <li><code>warning</code>: Bold yellow text</li> <li><code>progress</code>: (Custom handler, e.g., progress bars)</li> <li><code>stdout</code>: Dark green background</li> <li><code>stderr</code>: Dark red background</li> </ul>"},{"location":"reference/rich-message-handler/#example-usage","title":"Example Usage","text":"<pre><code>handler = RichMessageHandler()\nhandler.handle_message({\"type\": \"success\", \"message\": \"\u2705 File created\"})\nhandler.handle_message({\"type\": \"content\", \"message\": \"**Hello!** This is Markdown.\"})\n</code></pre>"},{"location":"reference/rich-message-handler/#integration","title":"Integration","text":"<ul> <li>Used as the default message handler for CLI output in Janito.</li> <li>Honors the <code>trust</code> config to suppress non-content output for safer automation.</li> <li>Extensible: Add new message types or styles as needed.</li> </ul> <p>For the overall message handler model, see the Message Handler Model.</p>"},{"location":"tools/search-text/","title":"\ud83d\udd0d search_text","text":"<p>Search for a text query in all files within one or more directories or file paths and return matching lines or counts. Respects <code>.gitignore</code>.</p>"},{"location":"tools/search-text/#signature","title":"Signature","text":"<pre><code>search_text(\n    paths: str,\n    query: str,\n    use_regex: bool = False,\n    case_sensitive: bool = False,\n    max_depth: int = 0,\n    max_results: int = 100,\n    count_only: bool = False,\n) -&gt; str\n</code></pre>"},{"location":"tools/search-text/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>paths</code> <code>str</code> required Space-separated list of file or directory paths to search in. <code>query</code> <code>str</code> required Text or regular expression to search for. Must not be empty. <code>use_regex</code> <code>bool</code> <code>False</code> If <code>True</code>, treat <code>query</code> as a regular expression. If <code>False</code>, treat as plain text. <code>case_sensitive</code> <code>bool</code> <code>False</code> If <code>False</code>, perform a case-insensitive search. <code>max_depth</code> <code>int</code> <code>0</code> Maximum directory depth to search. <code>0</code> = unlimited recursion. <code>1</code> = top-level only. <code>max_results</code> <code>int</code> <code>100</code> Maximum number of matching lines to return. <code>0</code> = no limit. <code>count_only</code> <code>bool</code> <code>False</code> If <code>True</code>, return only match counts instead of the actual lines."},{"location":"tools/search-text/#returns","title":"Returns","text":"<ul> <li>Lines mode (<code>count_only=False</code>): newline-separated list of matches, each formatted as:   <code>filepath:lineno: line content</code></li> <li>Count mode (<code>count_only=True</code>): summary of matches per file plus a total.</li> </ul>"},{"location":"tools/search-text/#examples","title":"Examples","text":""},{"location":"tools/search-text/#plain-text-search","title":"Plain-text search","text":"<pre><code>search_text(paths=\"src\", query=\"TODO\")\n</code></pre>"},{"location":"tools/search-text/#regex-search","title":"Regex search","text":"<pre><code>search_text(paths=\"src tests\", query=r\"def\\s+\\w+\", use_regex=True)\n</code></pre>"},{"location":"tools/search-text/#case-insensitive-count","title":"Case-insensitive count","text":"<pre><code>search_text(paths=\"docs\", query=\"janito\", case_sensitive=False, count_only=True)\n</code></pre>"},{"location":"tools/search-text/#limit-depth","title":"Limit depth","text":"<pre><code>search_text(paths=\".\", query=\"import\", max_depth=1)\n</code></pre>"},{"location":"tools/search-text/#unlimited-results","title":"Unlimited results","text":"<pre><code>search_text(paths=\".\", query=\"print\", max_results=0)\n</code></pre>"}]}